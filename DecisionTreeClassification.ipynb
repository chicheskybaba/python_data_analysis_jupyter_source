{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b43cadd-ac75-490c-aae3-357eb264fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8a86e-4fd7-451a-9793-a5692950718d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0488b999-277f-4326-b3c7-fe1d8a124278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1357</td>\n",
       "      <td>With all three Clintons in Iowa, a glimpse at ...</td>\n",
       "      <td>CEDAR RAPIDS, Iowa — “I had one of the most wo...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>988</td>\n",
       "      <td>Donald Trump’s Shockingly Weak Delegate Game S...</td>\n",
       "      <td>Donald Trump’s organizational problems have go...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7041</td>\n",
       "      <td>Strong Solar Storm, Tech Risks Today | S0 News...</td>\n",
       "      <td>Click Here To Learn More About Alexandra's Per...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7623</td>\n",
       "      <td>10 Ways America Is Preparing for World War 3</td>\n",
       "      <td>October 31, 2016 at 4:52 am \\nPretty factual e...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1571</td>\n",
       "      <td>Trump takes on Cruz, but lightly</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4739</td>\n",
       "      <td>How women lead differently</td>\n",
       "      <td>As more women move into high offices, they oft...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7737</td>\n",
       "      <td>Shocking! Michele Obama &amp; Hillary Caught Glamo...</td>\n",
       "      <td>Shocking! Michele Obama &amp; Hillary Caught Glamo...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8716</td>\n",
       "      <td>Hillary Clinton in HUGE Trouble After America ...</td>\n",
       "      <td>0 \\nHillary Clinton has barely just lost the p...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3304</td>\n",
       "      <td>What's in that Iran bill that Obama doesn't like?</td>\n",
       "      <td>Washington (CNN) For months, the White House a...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3078</td>\n",
       "      <td>The 1 chart that explains everything you need ...</td>\n",
       "      <td>While paging through Pew's best data visualiza...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              title  \\\n",
       "0         8476                       You Can Smell Hillary’s Fear   \n",
       "1        10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2         3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3        10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4          875   The Battle of New York: Why This Primary Matters   \n",
       "5         6903                                        Tehran, USA   \n",
       "6         7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7           95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8         4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9         2909  Iran reportedly makes new push for uranium con...   \n",
       "10        1357  With all three Clintons in Iowa, a glimpse at ...   \n",
       "11         988  Donald Trump’s Shockingly Weak Delegate Game S...   \n",
       "12        7041  Strong Solar Storm, Tech Risks Today | S0 News...   \n",
       "13        7623       10 Ways America Is Preparing for World War 3   \n",
       "14        1571                   Trump takes on Cruz, but lightly   \n",
       "15        4739                         How women lead differently   \n",
       "16        7737  Shocking! Michele Obama & Hillary Caught Glamo...   \n",
       "17        8716  Hillary Clinton in HUGE Trouble After America ...   \n",
       "18        3304  What's in that Iran bill that Obama doesn't like?   \n",
       "19        3078  The 1 chart that explains everything you need ...   \n",
       "\n",
       "                                                 text label  \n",
       "0   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1   Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3   — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4   It's primary day in New York and front-runners...  REAL  \n",
       "5     \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6   Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7   A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8   Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9   Iranian negotiators reportedly have made a las...  REAL  \n",
       "10  CEDAR RAPIDS, Iowa — “I had one of the most wo...  REAL  \n",
       "11  Donald Trump’s organizational problems have go...  REAL  \n",
       "12  Click Here To Learn More About Alexandra's Per...  FAKE  \n",
       "13  October 31, 2016 at 4:52 am \\nPretty factual e...  FAKE  \n",
       "14  Killing Obama administration rules, dismantlin...  REAL  \n",
       "15  As more women move into high offices, they oft...  REAL  \n",
       "16  Shocking! Michele Obama & Hillary Caught Glamo...  FAKE  \n",
       "17  0 \\nHillary Clinton has barely just lost the p...  FAKE  \n",
       "18  Washington (CNN) For months, the White House a...  REAL  \n",
       "19  While paging through Pew's best data visualiza...  REAL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df=pd.read_csv('news.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21da2a56-4cd7-4cab-9a64-bd65cbce67f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6335 non-null   int64 \n",
      " 1   title       6335 non-null   object\n",
      " 2   text        6335 non-null   object\n",
      " 3   label       6335 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 198.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# View the info of the data frame.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a6c71e-6ebd-4e48-a6f2-623b8c61d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows and columns.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b1a43a-a5ac-41ca-b3c4-c27ba5493453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5280.415627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3038.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2674.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10557.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0\n",
       "count   6335.000000\n",
       "mean    5280.415627\n",
       "std     3038.503953\n",
       "min        2.000000\n",
       "25%     2674.500000\n",
       "50%     5271.000000\n",
       "75%     7901.000000\n",
       "max    10557.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the statistical informationa about the dataset.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0fd129-15e6-45e5-a7f4-dd06f5d5aab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "title         0\n",
       "text          0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values. Use the is null method for it.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767532c7-f2f4-4e39-b2c0-9490c141782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that all values are 0. It shows that there are no null values in the dataset. \n",
    "# So we can move further without changing anything in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b69cd18b-13de-412e-be83-57471a9b5a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          You Can Smell Hillary’s Fear   \n",
       "1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           Kerry to go to Paris in gesture of sympathy   \n",
       "3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "4      The Battle of New York: Why This Primary Matters   \n",
       "...                                                 ...   \n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop this unnamed column using the drop method.\n",
    "\n",
    "# Let's drop unimportant columns.\n",
    "\n",
    "df_drop = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "df_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a87e72d-1ba4-4a18-81e5-de0eb821781c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us see how much Real news and how much Fake news was there in the dataset. The value counts method actually returns \n",
    "# the count of a particular variable in a given feature.\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30abe2d-5a33-4156-b821-50d1c6c011ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are 3171 Real news and 3164 Fake news. OMG!! probability is almost 0.5 for the news being fake so, \n",
    "# be aware of them.\n",
    "\n",
    "# Data Visualizations\n",
    "\n",
    "# Visualize the count plot using the seaborn library.\n",
    "\n",
    "plt.figure(figsize=(5,10));\n",
    "sns.countplot(df['label']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f73fda0-6df1-4cf0-ae2a-7e379fe5b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the graph, we can see that both are almost similar.\n",
    "\n",
    "# Define x and y.\n",
    "\n",
    "# For creating a model, first, we have to define x and y in which x contains all independent features of the dataset \n",
    "# and y contains a dependent feature that is labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3211ac90-1c26-4dc2-835c-4da80bab932e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8fbe68-c1ab-4e8e-a7f3-0d04d5fe5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[ : , :-1].values\n",
    "y = df.iloc[ : , -1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e04bb3d-6d54-4f94-a571-ab8b9603aa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8476, 'You Can Smell Hillary’s Fear',\n",
       "        'Daniel Greenfield, a Shillman Journalism Fellow at the Freedom Center, is a New York writer focusing on radical Islam. \\nIn the final stretch of the election, Hillary Rodham Clinton has gone to war with the FBI. \\nThe word “unprecedented” has been thrown around so often this election that it ought to be retired. But it’s still unprecedented for the nominee of a major political party to go war with the FBI. \\nBut that’s exactly what Hillary and her people have done. Coma patients just waking up now and watching an hour of CNN from their hospital beds would assume that FBI Director James Comey is Hillary’s opponent in this election. \\nThe FBI is under attack by everyone from Obama to CNN. Hillary’s people have circulated a letter attacking Comey. There are currently more media hit pieces lambasting him than targeting Trump. It wouldn’t be too surprising if the Clintons or their allies were to start running attack ads against the FBI. \\nThe FBI’s leadership is being warned that the entire left-wing establishment will form a lynch mob if they continue going after Hillary. And the FBI’s credibility is being attacked by the media and the Democrats to preemptively head off the results of the investigation of the Clinton Foundation and Hillary Clinton. \\nThe covert struggle between FBI agents and Obama’s DOJ people has gone explosively public. \\nThe New York Times has compared Comey to J. Edgar Hoover. Its bizarre headline, “James Comey Role Recalls Hoover’s FBI, Fairly or Not” practically admits up front that it’s spouting nonsense. The Boston Globe has published a column calling for Comey’s resignation. Not to be outdone, Time has an editorial claiming that the scandal is really an attack on all women. \\nJames Carville appeared on MSNBC to remind everyone that he was still alive and insane. He accused Comey of coordinating with House Republicans and the KGB. And you thought the “vast right wing conspiracy” was a stretch. \\nCountless media stories charge Comey with violating procedure. Do you know what’s a procedural violation? Emailing classified information stored on your bathroom server. \\nSenator Harry Reid has sent Comey a letter accusing him of violating the Hatch Act. The Hatch Act is a nice idea that has as much relevance in the age of Obama as the Tenth Amendment. But the cable news spectrum quickly filled with media hacks glancing at the Wikipedia article on the Hatch Act under the table while accusing the FBI director of one of the most awkward conspiracies against Hillary ever. \\nIf James Comey is really out to hurt Hillary, he picked one hell of a strange way to do it. \\nNot too long ago Democrats were breathing a sigh of relief when he gave Hillary Clinton a pass in a prominent public statement. If he really were out to elect Trump by keeping the email scandal going, why did he trash the investigation? Was he on the payroll of House Republicans and the KGB back then and playing it coy or was it a sudden development where Vladimir Putin and Paul Ryan talked him into taking a look at Anthony Weiner’s computer? \\nEither Comey is the most cunning FBI director that ever lived or he’s just awkwardly trying to navigate a political mess that has trapped him between a DOJ leadership whose political futures are tied to Hillary’s victory and his own bureau whose apolitical agents just want to be allowed to do their jobs. \\nThe only truly mysterious thing is why Hillary and her associates decided to go to war with a respected Federal agency. Most Americans like the FBI while Hillary Clinton enjoys a 60% unfavorable rating. \\nAnd it’s an interesting question. \\nHillary’s old strategy was to lie and deny that the FBI even had a criminal investigation underway. Instead her associates insisted that it was a security review. The FBI corrected her and she shrugged it off. But the old breezy denial approach has given way to a savage assault on the FBI. \\nPretending that nothing was wrong was a bad strategy, but it was a better one that picking a fight with the FBI while lunatic Clinton associates try to claim that the FBI is really the KGB. \\nThere are two possible explanations. \\nHillary Clinton might be arrogant enough to lash out at the FBI now that she believes that victory is near. The same kind of hubris that led her to plan her victory fireworks display could lead her to declare a war on the FBI for irritating her during the final miles of her campaign. \\nBut the other explanation is that her people panicked. \\nGoing to war with the FBI is not the behavior of a smart and focused presidential campaign. It’s an act of desperation. When a presidential candidate decides that her only option is to try and destroy the credibility of the FBI, that’s not hubris, it’s fear of what the FBI might be about to reveal about her. \\nDuring the original FBI investigation, Hillary Clinton was confident that she could ride it out. And she had good reason for believing that. But that Hillary Clinton is gone. In her place is a paranoid wreck. Within a short space of time the “positive” Clinton campaign promising to unite the country has been replaced by a desperate and flailing operation that has focused all its energy on fighting the FBI. \\nThere’s only one reason for such bizarre behavior. \\nThe Clinton campaign has decided that an FBI investigation of the latest batch of emails poses a threat to its survival. And so it’s gone all in on fighting the FBI. It’s an unprecedented step born of fear. It’s hard to know whether that fear is justified. But the existence of that fear already tells us a whole lot. \\nClinton loyalists rigged the old investigation. They knew the outcome ahead of time as well as they knew the debate questions. Now suddenly they are no longer in control. And they are afraid. \\nYou can smell the fear. \\nThe FBI has wiretaps from the investigation of the Clinton Foundation. It’s finding new emails all the time. And Clintonworld panicked. The spinmeisters of Clintonworld have claimed that the email scandal is just so much smoke without fire. All that’s here is the appearance of impropriety without any of the substance. But this isn’t how you react to smoke. It’s how you respond to a fire. \\nThe misguided assault on the FBI tells us that Hillary Clinton and her allies are afraid of a revelation bigger than the fundamental illegality of her email setup. The email setup was a preemptive cover up. The Clinton campaign has panicked badly out of the belief, right or wrong, that whatever crime the illegal setup was meant to cover up is at risk of being exposed. \\nThe Clintons have weathered countless scandals over the years. Whatever they are protecting this time around is bigger than the usual corruption, bribery, sexual assaults and abuses of power that have followed them around throughout the years. This is bigger and more damaging than any of the allegations that have already come out. And they don’t want FBI investigators anywhere near it. \\nThe campaign against Comey is pure intimidation. It’s also a warning. Any senior FBI people who value their careers are being warned to stay away. The Democrats are closing ranks around their nominee against the FBI. It’s an ugly and unprecedented scene. It may also be their last stand. \\nHillary Clinton has awkwardly wound her way through numerous scandals in just this election cycle. But she’s never shown fear or desperation before. Now that has changed. Whatever she is afraid of, it lies buried in her emails with Huma Abedin. And it can bring her down like nothing else has.  '],\n",
       "       [10294,\n",
       "        'Watch The Exact Moment Paul Ryan Committed Political Suicide At A Trump Rally (VIDEO)',\n",
       "        'Google Pinterest Digg Linkedin Reddit Stumbleupon Print Delicious Pocket Tumblr \\nThere are two fundamental truths in this world: Paul Ryan desperately wants to be president. And Paul Ryan will never be president. Today proved it. \\nIn a particularly staggering example of political cowardice, Paul Ryan re-re-re-reversed course and announced that he was back on the Trump Train after all. This was an aboutface from where he was a few weeks ago. He had previously declared he would not be supporting or defending Trump after a tape was made public in which Trump bragged about assaulting women. Suddenly, Ryan was appearing at a pro-Trump rally and boldly declaring that he already sent in his vote to make him President of the United States. It was a surreal moment. The figurehead of the Republican Party dosed himself in gasoline, got up on a stage on a chilly afternoon in Wisconsin, and lit a match. . @SpeakerRyan says he voted for @realDonaldTrump : “Republicans, it is time to come home” https://t.co/VyTT49YvoE pic.twitter.com/wCvSCg4a5I \\n— ABC News Politics (@ABCPolitics) November 5, 2016 \\nThe Democratic Party couldn’t have asked for a better moment of film. Ryan’s chances of ever becoming president went down to zero in an instant. In the wreckage Trump is to leave behind in his wake, those who cravenly backed his campaign will not recover. If Ryan’s career manages to limp all the way to 2020, then the DNC will have this tape locked and loaded to be used in every ad until Election Day. \\nThe ringing endorsement of the man he clearly hates on a personal level speaks volumes about his own spinelessness. Ryan has postured himself as a “principled” conservative, and one uncomfortable with Trump’s unapologetic bigotry and sexism. However, when push came to shove, Paul Ryan – like many of his colleagues – turned into a sniveling appeaser. After all his lofty tak about conviction, his principles were a house of cards and collapsed with the slightest breeze. \\nWhat’s especially bizarre is how close Ryan came to making it through unscathed. For months the Speaker of the House refused to comment on Trump at all. His strategy seemed to be to keep his head down, pretend Trump didn’t exist, and hope that nobody remembered what happened in 2016. Now, just days away from the election, he screwed it all up. \\nIf 2016’s very ugly election has done any good it’s by exposing the utter cowardice of the Republicans who once feigned moral courage. A reality television star spit on them, hijacked their party, insulted their wives, and got every last one of them to kneel before him. What a turn of events. \\nFeatured image via Twitter'],\n",
       "       [3608, 'Kerry to go to Paris in gesture of sympathy',\n",
       "        'U.S. Secretary of State John F. Kerry said Monday that he will stop in Paris later this week, amid criticism that no top American officials attended Sunday’s unity march against terrorism.\\n\\nKerry said he expects to arrive in Paris Thursday evening, as he heads home after a week abroad. He said he will fly to France at the conclusion of a series of meetings scheduled for Thursday in Sofia, Bulgaria. He plans to meet the next day with Foreign Minister Laurent Fabius and President Francois Hollande, then return to Washington.\\n\\nThe visit by Kerry, who has family and childhood ties to the country and speaks fluent French, could address some of the criticism that the United States snubbed France in its darkest hour in many years.\\n\\nThe French press on Monday was filled with questions about why neither President Obama nor Kerry attended Sunday’s march, as about 40 leaders of other nations did. Obama was said to have stayed away because his own security needs can be taxing on a country, and Kerry had prior commitments.\\n\\nAmong roughly 40 leaders who did attend was Israeli Prime Minister Benjamin Netanyahu, no stranger to intense security, who marched beside Hollande through the city streets. The highest ranking U.S. officials attending the march were Jane Hartley, the ambassador to France, and Victoria Nuland, the assistant secretary of state for European affairs. Attorney General Eric H. Holder Jr. was in Paris for meetings with law enforcement officials but did not participate in the march.\\n\\nKerry spent Sunday at a business summit hosted by India’s prime minister, Narendra Modi. The United States is eager for India to relax stringent laws that function as barriers to foreign investment and hopes Modi’s government will act to open the huge Indian market for more American businesses.\\n\\nIn a news conference, Kerry brushed aside criticism that the United States had not sent a more senior official to Paris as “quibbling a little bit.” He noted that many staffers of the American Embassy in Paris attended the march, including the ambassador. He said he had wanted to be present at the march himself but could not because of his prior commitments in India.\\n\\n“But that is why I am going there on the way home, to make it crystal clear how passionately we feel about the events that have taken place there,” he said.\\n\\n“And I don’t think the people of France have any doubts about America’s understanding of what happened, of our personal sense of loss and our deep commitment to the people of France in this moment of trauma.”'],\n",
       "       ...,\n",
       "       [8622,\n",
       "        'Anti-Trump Protesters Are Tools of the Oligarchy     : Information',\n",
       "        \" Anti-Trump Protesters Are Tools of the Oligarchy \\x93Reform always provokes rage on the part of those who profit by the old order.\\x94 Arthur M. Schlesinger, Jr., The Crisis of the Old Order\\nBy Paul Craig Roberts\\n Who are the anti-Trump protesters besmirching the name of progressives by pretending to be progressives and by refusing to accept the outcome of the presidential election? They look like, and are acting worse than, the \\x93white trash\\x94 that they are denouncing.\\nI think I know who they are. They are thugs for hire and are paid by the Oligarchy to delegitimize Trump\\x92s presidency in the way that Washington and the German Marshall Fund paid students in Kiev to protest the democratically elected Ukrainian government in order to prepare the way for a coup.\\nThe organization, change.org, which claims to be a progressive group, but might be a front, along with other progressive groups, for the Oligarchy, is destroying the reputation of all progressives by circulating a petition that directs the electors of the Electoral Collage to annul the election by casting their votes for Hillary. Remember how upset progressives were when Trump said he might not accept the election result if there was evidence that the vote was rigged? Now progressives are doing what they damned Trump for saying he might do under certain conditions.\\nThe Western presstitutes used the protests in Kiev to delegitimize a democratically elected government and to set it up for a coup. The protest pay was good enough that non-Ukrainians came from nearby countries to participate in the protest in order to collect the money. At the time I posted the amounts paid daily to protesters. Reports came in to me from Eastern and Western Europe from people who were not Ukrainian but were paid to protest as if they were Ukrainians.\\nThe same thing is going on with the Trump protests. CNN reports that \\x93for many Americans across the country, Donald Trump\\x92s victory is an outcome they simply refuse to accept. Tens of thousands filled the streets in at least 25 US cities overnight.\\x94 This is the exact reporting that the Oligarchy desired from its presstitutes and got.\\nI hope no one thinks that simultaneous protests in 25 cities were a spontaneous event. How did 25 independent protests manage to come up with the same slogans and the same signs on the same night following the election?\\nWhat is the point of the protests, and what interest is served by them? As the Romans always asked, \\x93who benefits?\\x94\\nThere is only one answer: The Oligarchy and only the Oligarchy benefits.\\nTrump is a threat to the Oligarchy, because he intends to stop the giveaway of American jobs to foreigners. The jobs giveaway, sanctified by the neoliberal junk economists as \\x93free trade,\\x94 is one of the main reasons for the 21st century worsening of the US income distribution. Money that was formerly paid in middle class wages and salaries to American manufacturing employees and college graduates has been re-routed to the pockets of the One Percent.\\nWhen US corporations move their production of goods and services sold to Americans offshore to Asian countries, such as China and India, their wage bill falls. The money formerly paid in middle class incomes goes instead into executive bonuses and dividends and capital gains to shareholders. The ladders of upward mobility that had made America the land of opportunity were dismantled for the sole purpose of making a handful of people multi-billionaires.\\nTrump is a threat to the Oligarchy, because he intends peaceful relations with Russia. In order to replace the profitable Soviet Threat, the Oligarchy and their neoconservative agents worked overtime to recreate the \\x93Russian Threat\\x94 by demonizing Russia.\\nAccustomed to many decades of excess profits from the profitable Cold War, the military/security complex was angry when President Reagan brought the Cold War to an end. Before these leaches on American taxpayers could get the Cold War going again, the Soviet Union collapsed as a result of a right-wing coup against Soviet President Mikhail Gorbachev.\\nThe military/security complex and their zionist neoconservative agents cooked up \\x93the war on terror\\x94 to keep the money flowing to the One Percent. But as hard as the presstitute media worked to create fear of \\x93the Muslim threat,\\x94 even insouciant Americans knew that the Muslims did not have thousands of ICBMs carrying powerful thermo-nuclear weapons capable of destroying the entirety of the United States in a few minutes. Neither did the Muslims have the Red Army capable of overrunning all of Europe in a couple of days. Indeed, the Muslims haven\\x92t needed an army. Refugees from Washington\\x92s wars enabled by Europeans are overrunning Europe.\\nThe excuse for the annual trillion dollar ($1,000 billion ) military/security budget was missing. So the Oligarchy created \\x93the New Hitler\\x94 in Russia. Hillary was the Oligarchy\\x92s principle agent for heating up the new Cold War.\\nHillary is the tool, enriched by the Oligarchy, whose job as President was to protect and to increase the trillion dollar budget of the military/security complex. With Hillary in the White House, the looting of the American taxpayers in behalf of the wealth of the One Percent could go forward unimpeded. But if Trump resolves \\x93the Russian threat,\\x94 the Oligarchy takes an income hit.\\nHillary\\x92s job as President was also to privatize Social Security in order that her Wall Street benefactors can rip off Americans the way that Americans have been ripped off by the insurance companies under Obamacare.\\nThose Americans who do not pay attention think, mistakenly, that the FBI cleared Hillary of violating National Security protocols with her email practices. The FBI said that Hillary did violate National Security, but that it was a result of carelessness or ignorance. She got off from indictment, because the FBI concluded that she did not intentionally violate National Security protocols. The investigation of the Clinton Foundation continues.\\nIn other words, in order to protect Hillary the FBI fell back on the ancient common law rule that \\x93there can be no crime without intent.\\x94 (See PCR and Lawrence Stratton, The Tyranny of Good Intentions .)\\nOne would think that protesters, if they were legitimate, would be celebrating Trump\\x92s victory. He, unlike Hillary, promises to reduce tensions with powerful Russia, and we hope also with China. Unlike Hillary, Trump says he is concerned with the absence of careers for those very people protesting in the streets of 25 cities against him.\\nIn other words, the protests against the American people for electing Trump as their president are pointless. The protests are happening for one reason only. The Oligarchy intends to delegitimize the Trump Presidency. Once President Trump is delegitimized, it will be easier for the Oligarchy to assassinate him. Unless the Oligarchy can appoint and control Trump\\x92s government, Trump is a prime candidate for assassination.\\nThe protests against Trump are suspicious for another reason. Unlike Hillary, Obama, and George W. Bush, Donald Trump has not slaughtered and dislocated millions of peoples in seven countries, sending millions of refugees from the Oligarchy\\x92s wars to overrun Europe.\\nTrump earned his fortune, and if by hook or crook, not by selling US government influence to foreign agents as Bill and Hillary did.\\nSo what are the protesters protesting?\\nThere is no answer except that they are hired to protest. Just as the Maidan protesters in Kiev were hired to protest by US and German financed NGOs.\\nThe protests in Kiev were equally pointless, because presidential elections were only months away. If Ukrainians really believed that their president was conspiring with Russia to keep Ukraine from becoming a Western puppet state and wished to become a puppet state regardless of the costs, the opportunity to vote the government out was at hand. The only reason for the protests was to orchestrate a coup. The US did succeed in putting their agent in control of the new Ukrainian government as Victoria Nuland and the US ambassador in Kiev confirmed in their telephone conversation that is available on the Internet.\\nThe Maidan protests were pointless except for making a coup possible. The protests were without any doubt arranged by Washington through Assistant Secretary of State Victoria Nuland, a neoconservative brought into the State Department by Hillary Clinton for the purpose of creating conflict with Russia.\\nTrump is being protested in order to make him vulnerable in the event he proves to be the threat to the Oligarchy that he is thought to be.\\nTrump won the presidency, but the Oligarchy is still in power, which makes any real reforms difficult to achieve. Symbolic reforms can be the product of the contest between President Trump and the oligarchs.\\nKarl Marx learned from historical experience, and Lenin, Stalin, and Pol Pot learned from Karl Marx, that change cannot occur if the displaced ruling class is left intact after a revolution against them. We have proof of this throughout South America. Every revolution by the indigenous people has left unmolested the Spanish ruling class, and every revolution has been overthrown by collusion between the ruling class and Washington.\\nWashington has conspired with traditional elites to remove the elected presidents of Honduras on a number of occasions. Recently, Washington helped elites evict the female presidents of Argentina and Brazil. The presidents of Venezuela, Ecuador, and Bolivia are in the crosshairs and are unlikely to survive. Washington is determined to get its hands on Julian Assange. To achieve this Washington intends to overthrow the Ecuadoran government that, in defiance of Washington, gave Julian Assange political asylum.\\nHugo Chavez had the power to exile or to exterminate the Spanish ruling class in Venezuela when the ruling class participated in a CIA coup against Chavez. But before the CIA could kill Chavez, the people and the military forced his release. Instead of punishing the criminals who would have murdered him, Chavez let them go.\\nAccording to Marx, Lenin, and Stalin, this is the classic mistake of the revolutionary. To rely on good will from the overthrown ruling class is the certain road to the defeat of the revolution.\\nLatin American has proved itself unable to learn this lesson: Revolutions cannot be conciliatory.\\nTrump is a dealmaker. The Oligarchy can permit him the sheen of success in exchange for no real change.\\nTrump is not perfect. He might fail on his own. But we should back him on the two most important elements in his program: to reduce tensions between the major nuclear powers, and to halt Washington\\x92s policy of permitting globalism to destroy Americans\\x92 economic prospects.\\nIf tensions between nuclear powers worsen, we won\\x92t be here to worry about other problems. The combination of the economy hollowed out by globalism and immigration is an economic nightmare. That Trump understands this is reason to support him.\\nNote: Some believe that Trump is a ruse conducted by the Oligarchy. However, as Hillary is the bought-and-paid-for representative of the Oligarchy, such an elaborate ruse is unnecessary. It is preferable for the Oligarchy to win on its own platform than to install a president on the opposite platform and then change him around. Another sellout increases the anger of the people. If Hillary had won, the Oligarchy would have had the voters\\x92 mandate for their platform.\\nDr. Paul Craig Roberts was Assistant Secretary of the Treasury for Economic Policy and associate editor of the Wall Street Journal. He was columnist for Business Week, Scripps Howard News Service, and Creators Syndicate. He has had many university appointments. His internet columns have attracted a worldwide following. Roberts' latest books are The Failure of Laissez Faire Capitalism and Economic Dissolution of the West , How America Was Lost , and The Neoconservative Threat to World Order .\"],\n",
       "       [4021,\n",
       "        'In Ethiopia, Obama seeks progress on peace, security in East Africa',\n",
       "        'ADDIS ABABA, Ethiopia —President Obama convened a meeting with the leaders of several East African nations and the African Union on Monday in an effort to address the worsening situation in South Sudan, even as he met with Ethiopia’s prime minister to discuss how to strengthen human rights and democratic institutions here.\\n\\nWith no resolution in sight for the ongoing conflict in South Sudan, Obama brought together top officials from Ethiopia, Uganda, Kenya, Sudan and the A.U. to chart out a strategy in the event that the latest round of peace talks fail.\\n\\nAfrican nations, led by Ethiopia, have been trying to broker a peace in South Sudan through the Intergovernmental Authority on Development (IGAD), a regional body, and are almost ready to present a possible compromise to the warring parties. The two sides will have until Aug. 17 to respond to the proposal, but administration officials have little expectation that they will accept it.\\n\\nOn Monday, Obama praised the regional leaders for showing “extraordinary leadership in trying to address the continuing situation in South Sudan.” The group included Ethiopian Prime Minister Hailemariam Desalegn, Ugandan President Yoweri Museveni, Kenyan President Uhuru Kenyatta, African Union Chairperson Dlamini Zuma and Sudan’s minister of foreign affairs, Ibrahim Ghandour.\\n\\n“This gives me and the U.S. delegation an opportunity to learn from them what progress has been made, where there appears to be continued roadblocks and how we can partner with them to make progress,” Obama said. “Our hope is that we can actually bring about the kind of peace that the people of South Sudan so desperately need.”\\n\\nThe question of South Sudan — a nation that the United States helped bring into existence in 2011 after years of effort by both the George W. Bush and Obama administrations — has vexed American policymakers for years.\\n\\nIn December 2013, South Sudan President Salva Kiir accused Riek Machar, who had served as his vice president, of attempting a coup d’etat. The two had been longtime political rivals from different ethnic groups — Kiir is Dinka, Machar is a Nuer — who had come together to form a government when the country was first created.\\n\\nWhile tribal differences have helped fuel the conflict, the war has been largely focused on control of the nation’s oil fields, South Sudan’s primary source of revenue.\\n\\nPrinceton Lyman, U.S. special envoy for Sudan and South Sudan from 2011 to 2013, noted that when he first took over as envoy, the United States had spent $10 billion on peacekeeping and other assistance for the two nations, “and that was four years ago… This is a big investment,” he added.\\n\\nAt this point, more than 2.5 million people are facing food shortages, while roughly 1.5 million are displaced from their homes. An additional 520,000 South Sudanese have fled across the border into neighboring countries, including Ethiopia.\\n\\nThe conflict also poses a major economic problem for Kenya, which had major investments in South Sudan before the fighting broke out. The LAPSSET Corridor project was aimed at transporting oil from South Sudan to the Kenyan port of Lamu, and according to E.J. Hogendoorn, deputy program director for Africa at the International Crisis Group, the planned transportation and infrastructure development could have been an “engine of development\" for many parts of East Africa. \"Unfortunately, of course, that’s on hold because of the war,” he said.\\n\\nWhile Obama spent part of the afternoon addressing a regional conflict in Africa, he devoted the rest of the day to strengthening ties with Ethiopia, whose alliance with the United States dates back more than a century. But the current government has come under sharp criticism for its treatment of political opponents and journalists.\\n\\nObama is the first sitting U.S. president to visit Ethiopia.\\n\\nIn a news conference Monday afternoon, both Obama and Hailemariam said they had a frank discussion about Ethiopia\\'s human rights practices and the need for improvement. Ethiopia is Africa’s number two jailer of journalists, according to the Committee to Protect Journalists, and its ruling party won 100 percent of the seats in May’s parliamentary elections.\\n\\nWhite House national security adviser Susan Rice, asked last week whether she considered Ethiopia a democracy, replied, with irony: “One hundred percent.”\\n\\nBut during the news conference Obama twice referred to the Ethiopian government as “democratically elected.”\\n\\n“I don’t bite my tongue,” Obama said of raising concerns on these issues with Ethiopia. “But I do so from a position of respect.”\\n\\nHailemariam, for his part, said, “Our commitment to democracy is real, not skin deep.”\\n\\nBut he added later that people could not expect sweeping reforms given the fact that military rule ended just a couple of decades ago. “Something has to be understood: This is a fledgling democracy.”\\n\\nThe two leaders also discussed their collaboration on counterterrorism, an area in which Ethiopia has been an active leader. The White House announced Monday it will “work with Congress to provide approximately $465 million” this year in new training, equipment and capacity-building aid to its African allies.\\n\\nThe administration also said it would provide at least $40 million in assistance this fiscal year to combat violent extremism in East Africa. The money is intended to foster collaboration among security forces, law enforcement, government officials, community leaders and members of civil society, officials said.\\n\\nObama praised Ethiopia’s work to curb extremist activity but noted that its government had labeled some opposition groups as posing a greater threat than U.S. intelligence would indicate. “Our intelligence indicates while they may oppose the government, they have not tipped into terrorism,” he said.\\n\\nThe United States provides more than $600 million in\\xa0assistance to Ethiopia annually. The vast bulk of that — $490 million — comes from the U.S. Agency for International Development, while the rest is largely security-related. Last fiscal year, nearly $200 million went to health programs, while $163 million went to humanitarian aid.\\n\\nObama said Ethiopia “has proven itself a global leader” on development and over the past 15 years “has lifted millions of people out of poverty.”\\n\\n“To many people around the world, their image of Ethiopia remains stuck in the past, remembering drought and famine,” he said.\\n\\nThe two leaders appeared to have a friendly rapport throughout the news conference. Hailemariam described his country as scoring a series of firsts: Along with being “the cradle of mankind,” he said, “Ethiopia is the birthplace of coffee.” That elicited a smile from Obama.\\n\\nObama said he was impressed by the Ethiopian’s unusual pets. “I had a chance to see the famous lions that live on the grounds,\" he said. \"I’m considering getting some for the White House.” But he conceded that before he did that, “I’ll have to make sure my dogs are safe.”'],\n",
       "       [4330,\n",
       "        \"Jeb Bush Is Suddenly Attacking Trump. Here's Why That Matters\",\n",
       "        'Jeb Bush Is Suddenly Attacking Trump. Here\\'s Why That Matters\\n\\nJeb Bush isn\\'t pulling punches anymore when it comes to Donald Trump.\\n\\nThe former Florida governor has delicately danced around the billionaire businessman in the 2016 presidential primary so far. But the gloves came off this week when Bush called out Trump as a closet Democrat. He was trying to stunt Trump\\'s rise while attempting to recover his own political mojo.\\n\\n\"What Jeb is desperately trying to do is find his swagger right now,\" GOP strategist Ford O\\'Connell said. \"The knock against Jeb is that he\\'s low voltage and not willing to fight. The best way to shake those perceptions it to engage against the person who is in the media on a 24/7 loop.\"\\n\\nIt\\'s a change from Bush\\'s approach to this point. He hasn\\'t lobbed many direct attacks at Trump other than delicately condemning his criticism of Arizona Sen. John McCain\\'s war service and his attacks against Fox News\\' Megyn Kelly.\\n\\nEven in this month\\'s first debate, Bush swatted down a story that he had allegedly called Trump a \"buffoon\" and a \"clown,\" saying only that Trump\\'s language had been \"divisive.\" Trump called Bush \"a true gentleman.\"\\n\\nThe detente ended this week. So far, most of the top-tier candidates have avoided directly attacking Trump, treating him with kid gloves so as not to anger the part of the GOP base to which Trump appeals.\\n\\nIn other words, the very voters they need when, they hope, Trump fades.\\n\\nIn split-screen New Hampshire town halls this week, Bush and Trump volleyed attacks on each other. Bush took his most pointed jabs at the current front-runner, underscoring Trump\\'s past history as a Democrat and the liberal positions he used to hold.\\n\\n\"Mr. Trump doesn\\'t have a proven conservative record,\" Bush said, according to the Washington Post. \"He was a Democrat longer in the last decade than he was a Republican. He has given more money to Democrats than he\\'s given to Republicans.\"\\n\\nBush went on to attack Trump over his hard-line immigration proposal, arguing it was not just \"vitriolic\" but would have a massive price tag.\\n\\n\"Hundreds of billions of dollars of costs to implement his plans is not a conservative plan,\" Bush said. \"This is going to be my pitch: Let\\'s support someone who you don\\'t have to guess where he stands because he\\'s consistent, because he\\'s been governor, he\\'s consistently had the views that he has.\"\\n\\nOver the next few days, Bush continued the hits on social media.\\n\\nBut Trump, never one to miss a moment to retaliate, didn\\'t pull his punches, either. At his own town hall Wednesday, Trump blasted Bush as an unelectable \"low-energy person.\"\\n\\n\"You know what\\'s happening to Jeb\\'s crowd just down the street? They\\'re sleeping!\" Trump said to applause.\\n\\nSince then, Trump has also ramped up his attacks against Bush on Twitter.\\n\\nThe move to more hot rhetoric may have tripped Bush up, though. Consider his use of the phrase \"anchor babies.\" While immigration reform is something Bush is passionate about — and has even written a book about — he\\'s often criticized within the GOP as too liberal on the issue. Instead, a more combative Bush appeared to use the loaded phrase for the first time.\\n\\nHe was left struggling to defend his use of it. It may have been a signal that the attack-dog crouch he\\'s taking is still one that isn\\'t completely comfortable to Bush, who earlier said he wanted to campaign \"joyfully.\"\\n\\nOther candidates have embraced hitting Trump. Kentucky Sen. Rand Paul went after him forcefully in the debate, though his punch — that Trump was hedging his bets to support Hillary Clinton if she wins the presidency — didn\\'t appear to land.\\n\\nOther candidates like Ohio Gov. John Kasich demurred. In the earlier GOP debate that night, former Texas Gov. Rick Perry and businesswoman Carly Fiorina also jabbed at Trump.\\n\\nBush, though, needs to close the floodgates. He\\'s dropped in national polls as Trump has risen. And, in New Hampshire, where Bush once led, Trump and even newcomer Kasich have seen surges.\\n\\nCullen, a former New Hampshire GOP chairman, said the change in tone and tactics was a smart move for Bush, one that could help him in the Granite State.\\n\\n\"I think it\\'s good politics for Jeb,\" said Fergus Cullen, a former New Hampshire Republican Party chairman. \"There\\'s 25 percent of the Republicans who are entertained by Donald Trump. But there\\'s 60 percent of the party who say they won\\'t vote for him under any circumstances. Those aren\\'t Jeb Bush\\'s people to begin with. He\\'s trying to appeal to the other 60 percent by being the adult in the room and trying to govern.\"\\n\\nO\\'Connell agreed. He pointed out that even if this new approach is one that\\'s uncomfortable for Bush, it\\'s necessary.\\n\\n\"In a lot of elections, being the studious one would have worked,\" he said, \"but Trump has flipped the script.\"']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b445ad37-fd4a-45bc-9e1a-96794776af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'FAKE', 'REAL', ..., 'FAKE', 'REAL', 'REAL'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51948bdd-94d6-47fb-91d8-ec62c569c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "# As we are working with text data, we have to use a count vectorizer for it. It is actually used to transform our text \n",
    "# into a vector on the basis of the frequency of each word which means how many times the word is repeated in the entire text.\n",
    "\n",
    "# It is available in the sci-kit learn library.\n",
    "\n",
    "# Fit_transform is used on the training dataset because it will scale our training data and learn the scaling parameters. \n",
    "# With this, our model will learn the mean and variance of the features that are there in this training dataset. \n",
    "# These parameters are used to work with test data.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c5e8774-78cc-4261-b183-fdc85687b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer(stop_words=\"english\",max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "740b6f0d-43fd-4d43-828d-d07d9d39347e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x1\u001b[38;5;241m=\u001b[39m\u001b[43mvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtodense()\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1198\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1195\u001b[0m min_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_df\n\u001b[0;32m   1196\u001b[0m max_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features\n\u001b[1;32m-> 1198\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1202\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1110\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1109\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1112\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:104\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "x1=vect.fit_transform(x[:,0]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae5c859d-b608-4001-aebc-8ac924feb9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2=vect.fit_transform(x[:,1]).todense()\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b897258-8c54-4170-9d44-a6e08c6166ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da7c871b-5393-4855-8a16-410687de32a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'unnamed': 'id'}).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3e285a-e683-44e8-9e2c-68767fc95a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34fcefb0-ed1f-41b4-9b4b-2594445dbdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "column_names = collections.defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27ae428-4845-4499-b7fc-c51cfc9f2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keys\n",
    "for name in df.columns:\n",
    "    column_names[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c26748a-a460-436e-b795-349b4d80971a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str, {'Unnamed: 0': '', 'title': '', 'text': '', 'label': ''})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show dictionary\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abe43cde-6d9a-49e5-96d1-59ea611153e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['id', 'title', 'text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a326350-6224-43ce-b051-f6696c48a744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4d7530c-7650-4255-add3-c819a663225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last\n",
       "0  1   Alex  Anderson\n",
       "1  2    Amy  Ackerman\n",
       "2  3  Allen       Ali"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "data_a = {'id': ['1', '2', '3'],\n",
    "          'first': ['Alex', 'Amy', 'Allen'],\n",
    "          'last': ['Anderson', 'Ackerman', 'Ali']}\n",
    "dataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n",
    "dataframe_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d43a2-c76b-4db5-8fb0-80f35514ce30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46854ff3-6bbf-4d52-9f0f-a8967c8915b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Balwner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first     last\n",
       "0  4  Billy   Bonder\n",
       "1  5  Brian    Black\n",
       "2  6   Bran  Balwner"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "data_b = {'id': ['4', '5', '6'],\n",
    "          'first': ['Billy', 'Brian', 'Bran'],\n",
    "          'last': ['Bonder', 'Black', 'Balwner']}\n",
    "dataframe_b = pd.DataFrame(data_b, columns = ['id', 'first', 'last'])\n",
    "dataframe_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5d6dc06-acec-4148-8f51-75fc157f6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames by rows\n",
    "pdconcat = pd.concat([dataframe_a, dataframe_b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eabf7d7-9dff-4fe4-b2b8-eec10667f41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Balwner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last\n",
       "0  1   Alex  Anderson\n",
       "1  2    Amy  Ackerman\n",
       "2  3  Allen       Ali\n",
       "0  4  Billy    Bonder\n",
       "1  5  Brian     Black\n",
       "2  6   Bran   Balwner"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdconcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15689589-1c61-41dd-8af8-0bbf29310aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Balwner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last id  first     last\n",
       "0  1   Alex  Anderson  4  Billy   Bonder\n",
       "1  2    Amy  Ackerman  5  Brian    Black\n",
       "2  3  Allen       Ali  6   Bran  Balwner"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate DataFrames by columns\n",
    "pd.concat([dataframe_a, dataframe_b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab63ec-4227-43c3-b3f0-70d659ee1d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb148134-6e4a-4ef9-bcf1-ff30a7837414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amy Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen Keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name\n",
       "0           1   Amy Jones\n",
       "1           2  Allen Keys\n",
       "2           3  Alice Bees\n",
       "3           4  Tim Horton"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "employee_data = {'employee_id': ['1', '2', '3', '4'],\n",
    "                 'name': ['Amy Jones', 'Allen Keys', 'Alice Bees', \n",
    "                          'Tim Horton']}\n",
    "dataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id',\n",
    "                                                             'name'])\n",
    "\n",
    "dataframe_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf13b76-3053-40aa-9235-226b7c0931ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a231aaa-dd76-4243-aa3d-5fd41403ca29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id  total_sales\n",
       "0           3        23456\n",
       "1           4         2512\n",
       "2           5         2345\n",
       "3           6         1455"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "sales_data = {'employee_id': ['3', '4', '5', '6'],\n",
    "              'total_sales': [23456, 2512, 2345, 1455]}\n",
    "dataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id',\n",
    "                                                      'total_sales'])\n",
    "\n",
    "dataframe_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79737daa-0ece-4a00-8d56-edf8acc0cd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           3  Alice Bees        23456\n",
       "1           4  Tim Horton         2512"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6d0c10e-1c35-44a1-bfa5-8ee73b7243c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amy Jones</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen Keys</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1455.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           1   Amy Jones          NaN\n",
       "1           2  Allen Keys          NaN\n",
       "2           3  Alice Bees      23456.0\n",
       "3           4  Tim Horton       2512.0\n",
       "4           5         NaN       2345.0\n",
       "5           6         NaN       1455.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26df0dff-7556-4473-b06b-d3c1491200fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254c89f3-09d3-49ba-a200-51ef5416918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "                     [3, 4],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd4d74f-1617-41b6-a0f1-f19488385c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PolynomialFeatures object\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7006f4f-67a4-494b-a708-8da6b27152a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  3.,  4.,  6.,  9.],\n",
       "       [ 3.,  4.,  9., 12., 16.],\n",
       "       [ 2.,  3.,  4.,  6.,  9.],\n",
       "       [ 2.,  3.,  4.,  6.,  9.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create polynomial features\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d25d3a-6a1a-4029-b6b7-d7fcee8498e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Dystopia Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "      <td>0.03411</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>2.51738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "      <td>0.04884</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.43630</td>\n",
       "      <td>2.70201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>2.49204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "      <td>0.03880</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>2.46531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>0.03553</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>2.45176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country          Region  Happiness Rank  Happiness Score  \\\n",
       "0  Switzerland  Western Europe               1            7.587   \n",
       "1      Iceland  Western Europe               2            7.561   \n",
       "2      Denmark  Western Europe               3            7.527   \n",
       "3       Norway  Western Europe               4            7.522   \n",
       "4       Canada   North America               5            7.427   \n",
       "\n",
       "   Standard Error  Economy (GDP per Capita)   Family  \\\n",
       "0         0.03411                   1.39651  1.34951   \n",
       "1         0.04884                   1.30232  1.40223   \n",
       "2         0.03328                   1.32548  1.36058   \n",
       "3         0.03880                   1.45900  1.33095   \n",
       "4         0.03553                   1.32629  1.32261   \n",
       "\n",
       "   Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
       "0                   0.94143  0.66557                        0.41978   \n",
       "1                   0.94784  0.62877                        0.14145   \n",
       "2                   0.87464  0.64938                        0.48357   \n",
       "3                   0.88521  0.66973                        0.36503   \n",
       "4                   0.90563  0.63297                        0.32957   \n",
       "\n",
       "   Generosity  Dystopia Residual  \n",
       "0     0.29678            2.51738  \n",
       "1     0.43630            2.70201  \n",
       "2     0.34139            2.49204  \n",
       "3     0.34699            2.46531  \n",
       "4     0.45811            2.45176  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df_2015 = pd.read_csv('2015.csv')\n",
    "df_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7ae5a90-6944-406b-a8a0-92f2f6315551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "152adfb2-009a-4ef9-8f31-8ef00e3f192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.,  3.],\n",
       "       [ 2., -3.],\n",
       "       [-6.,  0.],\n",
       "       [ 1., -3.],\n",
       "       [-4., nan]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = np.array([[-2, 3],\n",
    "                      [2, -3],\n",
    "                      [-6, 0],\n",
    "                      [1, -3],\n",
    "                      [-4, np.nan]])\n",
    "\n",
    "features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e00dbee6-ebd9-4af6-894d-8245949499f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame(features1, columns=[\"feature_1\", \"feature_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "581e28fb-cc69-4181-a6f6-fb7dce5aca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         -2          3\n",
       "1          2         -3\n",
       "2         -6          0\n",
       "3          1         -3\n",
       "4         -4          3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "580a44ce-3eeb-4dcd-b765-7752ca8edd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make k-means clusterer\n",
    "clusterer = KMeans(3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3b23a-76b7-4e51-9b22-1300c5f6516c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fade9998-f7f0-48a7-b762-5a46316fd601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit clusterer\n",
    "clusterer.fit(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05c44af4-263e-4388-a94d-523a5285c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "dataframe[\"group\"] = clusterer.predict(features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e897629-170f-4c9b-b18d-8f989119b22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0         -2          3      0\n",
       "1          2         -3      1\n",
       "2         -6          0      2\n",
       "3          1         -3      1\n",
       "4         -4          3      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first few observations\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "868b78a4-b11f-45f4-847f-a7eb0941d59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.,  3.],\n",
       "       [ 2., -3.],\n",
       "       [-6.,  0.],\n",
       "       [ 1., -3.],\n",
       "       [-4., nan]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "671f23fa-0b81-4aec-b66b-b8abaed63554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.,  3.],\n",
       "       [ 2., -3.],\n",
       "       [-6.,  0.],\n",
       "       [ 1., -3.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1[~np.isnan(features1).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d5101-bed1-4075-a6ec-2b239339e2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install fancyimpute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71226f90-2fa7-417e-b71f-0e58d7fb67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "998cda84-2a69-4833-8832-e65269b2cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                         n_features = 2,\n",
    "                         random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffd81f6-48c0-4c48-828e-0828ca1b7acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.05837272,  4.48825769],\n",
       "       [-8.60973869, -3.72714879],\n",
       "       [ 1.37129721,  5.23107449],\n",
       "       ...,\n",
       "       [-1.91854276,  4.59578307],\n",
       "       [-1.79600465,  4.28743568],\n",
       "       [-6.97684609, -8.89498834]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfba8730-1f5b-4108-be56-cb6c0039ce53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89f1ea8a-3427-4b56-8ec9-d8a8ec239ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83f6ca64-1cad-42f2-a1f5-2c9934569e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87301861,  1.31426523],\n",
       "       [-0.67073178, -0.22369263],\n",
       "       [ 2.1048424 ,  1.45332359],\n",
       "       ...,\n",
       "       [ 1.18998798,  1.33439442],\n",
       "       [ 1.22406396,  1.27667052],\n",
       "       [-0.21664919, -1.19113343]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the features\n",
    "standardized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd4c863-23e9-44a9-807a-848e011551a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the first feature's first value with a missing value\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38b92cda-f260-48be-a0e0-e3d0bd2cb755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8730186113995938"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80d27720-98d8-43b8-973c-a60ede99a17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3142652289926346"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_value1 = standardized_features[0,1]\n",
    "true_value1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef9637c-ba03-4274-a9b4-c0bc5894b689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "standardized_features[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "763fbf9c-ef6b-4e27-be44-d2e7bde153d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the missing values in the feature matrix\n",
    "features_knn_imputed = KNN(k=5, verbose=0).fit_transform(standardized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e34fd3d-6176-4b7a-abe2-fc0c230bdb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: 1.0955332713113226\n"
     ]
    }
   ],
   "source": [
    "# Compare true and imputed values\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_knn_imputed[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50efa6-ee0e-4471-babc-21ea7c85e068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99e4b9-dbbe-4f2b-8381-680ba5eb8f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3787e5f1-7a8d-4a36-bc54-5c3cbdf4465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4342ce2c-126c-4497-886b-15aec041b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature \n",
    "\n",
    "feature = np.array([[\"Texas\"], \n",
    "                    [\"California\"],\n",
    "                    [\"Texas\"], \n",
    "                    [\"Delaware\"], \n",
    "                    [\"Texas\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ce91f5-1365-4481-b104-3aef4e14002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Texas'],\n",
       "       ['California'],\n",
       "       ['Texas'],\n",
       "       ['Delaware'],\n",
       "       ['Texas']], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b87c34e-fe23-45b2-b383-7975c7c20387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8cd0010-df9c-4c14-8830-14025fc9fd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09c4f7f7-99d3-4d9b-b71b-3093028bcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e3a93d6-f4d8-41d7-b148-48bd807d2a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables from feature\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d849f9-9360-4dce-9db9-caf107132c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoder \n",
    "one_hot = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7110388d-737e-479b-be86-6559b48bb4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode feature \n",
    "\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb954bfe-1efd-4136-8cab-9766f4825d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17abc0c5-801b-4073-8d60-b8a6b8804a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1deb6-c2ec-4402-84d1-81049c22f222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058415e6-e638-4f84-ba72-13363f99a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiclass feature\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"), \n",
    "                      (\"California\", \"Alabama\"),\n",
    "                      (\"Texas\", \"Florida\"),\n",
    "                      (\"Delware\", \"Florida\"),\n",
    "                      (\"Texas\", \"Alabama\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e58c2fdb-dcff-440d-9fdf-9140ebbf19ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Texas', 'Florida'),\n",
       " ('California', 'Alabama'),\n",
       " ('Texas', 'Florida'),\n",
       " ('Delware', 'Florida'),\n",
       " ('Texas', 'Alabama')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c4878db-4d0d-45bd-9071-06a061572a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiclass one-hot encoder\n",
    "one_hot_multiclass = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e69efe-bd4f-41da-93b0-b58717ef040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode multiclass feature\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eea6bc1e-86c6-47f1-a0cf-733ed9e81d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once again, we can see the classes with the classes_ method:\n",
    "# View classes\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ead7c-e15a-4346-a6c6-c54147fb8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad36501-eb1e-4f4c-94b2-81e00834bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cb313b-44c3-4f5d-9910-0c366353599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b3fd59-cb15-4676-a124-52f141550bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Score\n",
       "0     Low\n",
       "1     Low\n",
       "2  Medium\n",
       "3  Medium\n",
       "4    High"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15407937-493c-4cfe-96fa-8f5f4bb155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapper\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"High\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7a84243-b188-4775-877d-f10e512a66ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace feature values with scale\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8068171-6f3d-469f-a32a-2f8ea7728874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c3ce479-281a-428d-a23a-c980480c11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(num):\n",
    "    if type(num) == int:\n",
    "        sum=0\n",
    "        for x in range(0, num+1, 1):\n",
    "            sum = sum + x\n",
    "        return sum\n",
    "    else:\n",
    "        return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a55b532d-691b-414c-86ab-b73f44b0c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f3096-d677-4633-835e-3d01686a23e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1822db-f892-42f0-9c6c-b6e803d86967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def age_check(ages):\n",
    "    adult = []\n",
    "    for age in ages:\n",
    "        if age >= 18:\n",
    "            adult.append(age)\n",
    "        return age >= 18\n",
    "    \n",
    "ages = [4, 23, 32, 12, 88]\n",
    "print(age_check(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aee79c-5bc5-482f-b5be-b3311da77ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff8fd5c-f278-4d51-80c0-1e2e2a49074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = True\n",
    "\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7911365e-7375-4b51-927b-d1b98ea95ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shopping = [\"bread\",\"milk\", \"eggs\"]\n",
    "\n",
    "len(shopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7470c9d-f7c9-497f-8786-6e906f048c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bread', 'egg', 'onion', 'carrot', 'rice', 'beans']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = ['bread', 'egg', 'onion']\n",
    "list2 = ['carrot', 'rice', 'beans']\n",
    "\n",
    "list = list1 + list2\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a10388-0f16-4af6-b2a7-69eebc897cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bread', 'milk', 'eggs', 'apple']\n"
     ]
    }
   ],
   "source": [
    "shopping = [\"bread\",\"milk\", \"eggs\"]\n",
    "shopping.append(\"apple\")\n",
    "print(shopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f332adb-5515-443c-bac7-e9784e223c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bread', 'milk', 'eggs', 'apple']\n"
     ]
    }
   ],
   "source": [
    "shopping = []\n",
    "shopping.append('bread')\n",
    "shopping.append('milk')\n",
    "shopping.append('eggs')\n",
    "shopping.append('apple')\n",
    "print(shopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b633a952-c037-4afe-9d0a-e5378e12a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = [[1,2,3],\n",
    "     [4,5,6],\n",
    "     [7,8,9]]\n",
    "\n",
    "Y = [[10,11,12],\n",
    "     [13,14,15],\n",
    "     [16,17,18]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91e5381f-8f6b-43b0-abd2-be8989058445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([150, 75, 300, 220])\n"
     ]
    }
   ],
   "source": [
    "album_sales = {'barbara':150, 'aretha':75, 'madonna':300, 'mariah':220}\n",
    "print( album_sales.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a40e77c-4be1-4e2c-803f-ff2c7203ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial_sum(number):\n",
    "    n = 1\n",
    "    factorial = 0\n",
    "    while n in range(1, number+1, 1):\n",
    "        factorial = n*(n+1)\n",
    "        n = n + 1\n",
    "    return factorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "197f3e85-e673-4a23-99bf-76bac9f32fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial_sum(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74d07c2-4941-4c20-a053-3922fb4a47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a106df19-9028-4e03-bfd5-28ceba04bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some HTML code\n",
    "html = \"\"\"\n",
    "       <div class='full_name'><span style='font-weight:bold'>Masego</span> Azra</div>\"\n",
    "       \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2dbc9c2-fd2d-407e-b3d2-0a17eb41b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse html\n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a19a6e-781e-4309-aa57-306265314c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n       Masego Azra'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the div with the class \"full_name\", show text\n",
    "soup.find(\"div\", { \"class\" : \"full_name\" }).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61233f-54e9-415e-8baf-6f50f81eba98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b38a2b3-84d1-4b3f-8b88-fbcc40f0a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import unicodedata\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5e74d9-9d69-4e74-b708-97c367183a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "text_data = ['Hi!!!! I. Love. This. Song....',\n",
    "             '10000% Agree!!!! #LoveIT',\n",
    "             'Right?!?!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6f45ea-6094-4d63-8c99-5a97dd6e1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74bc9e8-ab36-490f-bf53-4c74fae1e6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each string, remove any punctuation characters\n",
    "[string.translate(punctuation) for string in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd36c846-32ed-40f5-a3dd-a5f699709a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ecc8a55-91fa-421e-a61b-78d0fc6b8c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04',\n",
       "               '2000-01-05', '2000-01-06', '2000-01-07'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('1/1/2000', periods=7)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f88f1e33-7b25-4744-a973-8236063e8aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0\n",
       "2000-01-02    1\n",
       "2000-01-03    2\n",
       "2000-01-04    3\n",
       "2000-01-05    4\n",
       "2000-01-06    5\n",
       "2000-01-07    6\n",
       "Freq: D, dtype: int32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(np.arange(7), index=dates)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13f1f22c-53df-43be-ba3c-560afe073373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8307f328-3037-4f4c-8b46-9e50d5f48a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python list\n",
    "my_list_nums = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "# Numpy array\n",
    "my_odd_nums = numpy.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19])\n",
    "# Pandas series\n",
    "my_series = pandas.Series(my_odd_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6b69545-432d-4758-9723-3dda415c086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2     5\n",
       "3     7\n",
       "4     9\n",
       "5    11\n",
       "6    13\n",
       "7    15\n",
       "8    17\n",
       "9    19\n",
       "dtype: int32"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8569d880-00c5-4981-9027-2f0680c24f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_odd_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "120f6c8c-2a4d-4010-80b0-cd415341a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c920c1-5c49-468f-a6b0-391cf3f30074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d17c7-b60d-45dd-92a4-c4e586ab50e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db63a521-3df0-45b4-8b85-7343e8661a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
    "                   'mask': ['red', 'purple'],\n",
    "                   'weapon': ['sai', 'bo staff']})\n",
    "\n",
    "data = df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2eac7db-7f0a-4066-ab85-922d566a5696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mask</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raphael</td>\n",
       "      <td>red</td>\n",
       "      <td>sai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donatello</td>\n",
       "      <td>purple</td>\n",
       "      <td>bo staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name    mask    weapon\n",
       "0    Raphael     red       sai\n",
       "1  Donatello  purple  bo staff"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d04b5f0-8515-483d-9a35-5795708e5699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name,mask,weapon\\r\\nRaphael,red,sai\\r\\nDonatello,purple,bo staff\\r\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9669f3f-c352-4973-9c56-7b1669e4f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554591e-45a1-4675-9db5-51afaa4f7739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "713778be-d180-4f6e-9dc8-4b69b8a884a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06eb6510-cf2d-4966-8512-06408738503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state    [Ohio, Ohio, Ohio, Nevada, Nevada]\n",
       "year         [2000, 2001, 2002, 2001, 2002]\n",
       "pop               [1.5, 1.7, 3.6, 2.4, 2.9]\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.Series(data)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ed685-b259-4249-b3a3-d0c0dc41e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85814476-f144-4d8b-afe3-e607dd04dec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b72d4-1ecc-4c95-a4c6-0fbddcbfa934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a03e1-6d8d-4c9b-b73b-b0f7c5b27a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684126f-7301-47f0-9135-1e9f927404d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bcac0f6c-709f-466a-a7d5-e8475c2adf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87f3588a-9621-4bbe-b793-90d67d6814fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = iris.data\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a4ae913-5dd9-474b-bdd8-e59dbb555c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = iris.target\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5309b917-b097-4a85-8d88-2688232630db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ea990a01-a917-4ca2-bfc2-f9378c9508a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range of candidate penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2935cc99-e183-4700-bc09-79663a3979d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range of candidate regularization hyperparameter values\n",
    "C = np.logspace(0, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea4b82f6-f4c8-4581-8028-1149c45db075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary hyperparameter candidates\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0fc80472-adb8-4a26-be45-e9b8db37720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad601bb8-b99f-4a65-b6e5-67e639872b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.97333333        nan 0.97333333        nan 0.98\n",
      "        nan 0.98              nan 0.98              nan 0.97333333\n",
      "        nan 0.97333333        nan 0.97333333        nan 0.97333333\n",
      "        nan 0.97333333]\n",
      "  warnings.warn(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5db2294e-57a2-467b-8035-477d910c7f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4231aaa4-241f-4f82-88fe-57b8e36b030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 7.742636826811269\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ea22479d-8914-4cc2-9e07-b5791d438a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1947c4d-960b-4123-bbff-0ce369c76dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10fcdc-c915-4f88-a838-82ec7e006439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199ce57-8940-4fb5-9d36-20a117198561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a859a5d3-9246-4c36-b37c-871099b6caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01199d2c-b3db-44b8-b9a1-db8f8e82d00f",
   "metadata": {},
   "source": [
    "K-FOLD CROSS VALIDATION USING SCIKIT LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c07c56e-83b0-4833-ad63-381d7c392930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d113ae2-e486-4be7-a1b9-56843463f0f0",
   "metadata": {},
   "source": [
    "pd.DATAFRAME TO np.ARRAY (SHOWING FEATURES & TARGET) COLUMNS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa0277-54dc-45c7-b42e-b822dac3d819",
   "metadata": {},
   "source": [
    "CONVERTING CATEGORICAL COLUMN TO CATEGORICAL NUMERICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bbfba-e1b5-474a-b6d9-0c6ca8102c30",
   "metadata": {},
   "source": [
    "DROPPING IRRELEVANT COLUMN & INDEX COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa6093-7d89-4367-851c-8af91b496075",
   "metadata": {},
   "source": [
    "# 11.1 Cross-Validating Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76f72fbe-7513-4f62-94b1-bc5d79ec7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.1 Cross-Validating Models\n",
    "# Problem\n",
    "# You want to evaluate how well your model will work in the real world.\n",
    "# Solution\n",
    "# Create a pipeline that preprocesses the data, trains the model, and then evaluates it using cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99e54334-3554-4d96-9f89-6f361079eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "colors=['#9db1f8','#217a36','#47bc8f','#947efd','#a4d835']\n",
    "sns.set_palette(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85315b84-e537-4530-b92d-97fa9ed083ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>846</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>33500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>219</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>132500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>588</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>84500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>465</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0      385    Male   35         20000          0\n",
       "1      681    Male   40         43500          0\n",
       "2      353    Male   49         74000          0\n",
       "3      895    Male   40        107500          1\n",
       "4      661    Male   25         79000          0\n",
       "5      846  Female   47         33500          1\n",
       "6      219  Female   46        132500          1\n",
       "7      588    Male   42         64000          0\n",
       "8       85  Female   30         84500          0\n",
       "9      465    Male   41         52000          0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"car_data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "86c07006-b5d8-40dd-84e8-36c37902bf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>23500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0        385       0   35         20000          0\n",
       "1        681       0   40         43500          0\n",
       "2        353       0   49         74000          0\n",
       "3        895       0   40        107500          1\n",
       "4        661       0   25         79000          0\n",
       "..       ...     ...  ...           ...        ...\n",
       "995      863       0   38         59000          0\n",
       "996      800       1   47         23500          0\n",
       "997      407       1   28        138500          1\n",
       "998      299       1   48        134000          1\n",
       "999      687       1   44         73500          0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = pd.factorize(df['Gender'])[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f24022c0-024e-4653-86c9-9d66ab09a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the relevant 3 column features and converting them numpy array of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9fef3b26-2269-4406-be60-96fa5c75efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(df[['Gender', 'Age', 'AnnualSalary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1550024c-7531-4b2e-9b07-467aa3ba1df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,     35,  20000],\n",
       "       [     0,     40,  43500],\n",
       "       [     0,     49,  74000],\n",
       "       ...,\n",
       "       [     1,     28, 138500],\n",
       "       [     1,     48, 134000],\n",
       "       [     1,     44,  73500]], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "53128c30-1d2f-47db-945b-d5eb3752bfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "460a57d2-98c3-4646-9a07-52405ba29ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array(df[['Purchased']])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "84eef0e2-f6fa-46f4-9a55-e588cb4f75cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target column (number of columns and rows)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "88903635-c81f-42c0-bd8e-f542aa51e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c5b7695c-ea51-401d-9059-ec24dccd69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standardizer\n",
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a695d0d4-fd8c-43fe-ad44-97012ed28686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression object\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f51b54ec-5955-4d75-b48d-a360abbee9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2bd75fe6-d5de-4eda-805f-706eed4e4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "431ff853-e566-4ba4-ae86-37f0ac41723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features, # Feature matrix\n",
    "                             target, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4ed927d1-ee59-4904-bf54-5537c735dae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89, 0.82, 0.75, 0.89, 0.75, 0.86, 0.83, 0.82, 0.82, 0.88])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0810a419-84b7-4401-a2b8-1746c5fe0a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8310000000000001"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8dc40-75b4-4fd9-bc76-878ea1fafa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a9bdcd-4dfa-4326-9c94-646476589b37",
   "metadata": {},
   "source": [
    "# 11.2 Creating a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2f8d81a-7718-4757-93a7-e3452bd81d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Dystopia Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "      <td>0.03411</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>2.51738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "      <td>0.04884</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.43630</td>\n",
       "      <td>2.70201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>2.49204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "      <td>0.03880</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>2.46531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>0.03553</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>2.45176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country          Region  Happiness Rank  Happiness Score  \\\n",
       "0  Switzerland  Western Europe               1            7.587   \n",
       "1      Iceland  Western Europe               2            7.561   \n",
       "2      Denmark  Western Europe               3            7.527   \n",
       "3       Norway  Western Europe               4            7.522   \n",
       "4       Canada   North America               5            7.427   \n",
       "\n",
       "   Standard Error  Economy (GDP per Capita)   Family  \\\n",
       "0         0.03411                   1.39651  1.34951   \n",
       "1         0.04884                   1.30232  1.40223   \n",
       "2         0.03328                   1.32548  1.36058   \n",
       "3         0.03880                   1.45900  1.33095   \n",
       "4         0.03553                   1.32629  1.32261   \n",
       "\n",
       "   Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
       "0                   0.94143  0.66557                        0.41978   \n",
       "1                   0.94784  0.62877                        0.14145   \n",
       "2                   0.87464  0.64938                        0.48357   \n",
       "3                   0.88521  0.66973                        0.36503   \n",
       "4                   0.90563  0.63297                        0.32957   \n",
       "\n",
       "   Generosity  Dystopia Residual  \n",
       "0     0.29678            2.51738  \n",
       "1     0.43630            2.70201  \n",
       "2     0.34139            2.49204  \n",
       "3     0.34699            2.46531  \n",
       "4     0.45811            2.45176  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df_2015 = pd.read_csv('2015.csv')\n",
    "df_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0d7af2f-ead0-4b95-966d-cc1ecc5f671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 12)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66e3063c-8f50-4f5e-baf3-7f3ccd0a9eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.587  , 0.03411, 1.39651, ..., 0.66557, 0.41978, 0.29678],\n",
       "       [7.561  , 0.04884, 1.30232, ..., 0.62877, 0.14145, 0.4363 ],\n",
       "       [7.527  , 0.03328, 1.32548, ..., 0.64938, 0.48357, 0.34139],\n",
       "       ...,\n",
       "       [3.006  , 0.05015, 0.6632 , ..., 0.15684, 0.18906, 0.47179],\n",
       "       [2.905  , 0.08658, 0.0153 , ..., 0.1185 , 0.10062, 0.19727],\n",
       "       [2.839  , 0.06727, 0.20868, ..., 0.36453, 0.10731, 0.16681]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the data into features and target.\n",
    "# Convert the dataset into numpy array.\n",
    "# Drop irrelevant columns in the dataset\n",
    "import numpy as np\n",
    "features1 = np.array(df_2015[['Happiness Score', 'Standard Error', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)', 'Generosity']])\n",
    "features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c9fee689-2ff2-4d68-a360-8203ec43c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c59ec125-ff55-4c2f-a062-61e3e7a7a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.51738],\n",
       "       [2.70201],\n",
       "       [2.49204],\n",
       "       [2.46531],\n",
       "       [2.45176],\n",
       "       [2.61955],\n",
       "       [2.4657 ],\n",
       "       [2.37119],\n",
       "       [2.26425],\n",
       "       [2.26646],\n",
       "       [3.08854],\n",
       "       [3.17728],\n",
       "       [2.5332 ],\n",
       "       [3.60214],\n",
       "       [2.51011],\n",
       "       [3.26001],\n",
       "       [1.96961],\n",
       "       [1.9757 ],\n",
       "       [2.41484],\n",
       "       [2.24743],\n",
       "       [1.96994],\n",
       "       [2.47489],\n",
       "       [3.19131],\n",
       "       [1.88501],\n",
       "       [2.84848],\n",
       "       [2.11569],\n",
       "       [2.67585],\n",
       "       [1.55674],\n",
       "       [2.21126],\n",
       "       [2.836  ],\n",
       "       [2.67782],\n",
       "       [2.32142],\n",
       "       [2.85737],\n",
       "       [2.31945],\n",
       "       [2.43872],\n",
       "       [2.12367],\n",
       "       [1.6488 ],\n",
       "       [2.32323],\n",
       "       [1.87634],\n",
       "       [2.79094],\n",
       "       [2.26882],\n",
       "       [3.035  ],\n",
       "       [2.74255],\n",
       "       [2.23741],\n",
       "       [2.24639],\n",
       "       [1.68435],\n",
       "       [2.21978],\n",
       "       [2.53942],\n",
       "       [1.73797],\n",
       "       [2.02518],\n",
       "       [2.82334],\n",
       "       [3.10712],\n",
       "       [2.18896],\n",
       "       [2.24729],\n",
       "       [1.61583],\n",
       "       [2.44649],\n",
       "       [2.32407],\n",
       "       [2.5945 ],\n",
       "       [2.1309 ],\n",
       "       [1.86565],\n",
       "       [1.88541],\n",
       "       [2.75414],\n",
       "       [2.09066],\n",
       "       [2.27394],\n",
       "       [2.32038],\n",
       "       [1.59888],\n",
       "       [1.88931],\n",
       "       [2.43209],\n",
       "       [2.76579],\n",
       "       [1.86984],\n",
       "       [1.76145],\n",
       "       [0.65429],\n",
       "       [1.58782],\n",
       "       [1.86399],\n",
       "       [2.20173],\n",
       "       [2.08528],\n",
       "       [2.2327 ],\n",
       "       [2.89319],\n",
       "       [1.63794],\n",
       "       [2.00073],\n",
       "       [3.10709],\n",
       "       [1.87996],\n",
       "       [2.10017],\n",
       "       [1.8604 ],\n",
       "       [2.6343 ],\n",
       "       [1.93129],\n",
       "       [2.025  ],\n",
       "       [1.26462],\n",
       "       [1.62215],\n",
       "       [1.7536 ],\n",
       "       [2.11032],\n",
       "       [2.45373],\n",
       "       [1.73933],\n",
       "       [3.05137],\n",
       "       [1.89894],\n",
       "       [2.06367],\n",
       "       [2.79832],\n",
       "       [1.21305],\n",
       "       [1.73799],\n",
       "       [1.34759],\n",
       "       [2.48676],\n",
       "       [1.80101],\n",
       "       [1.57059],\n",
       "       [1.24074],\n",
       "       [1.84408],\n",
       "       [2.11399],\n",
       "       [2.12466],\n",
       "       [2.04384],\n",
       "       [2.51767],\n",
       "       [1.6944 ],\n",
       "       [1.5714 ],\n",
       "       [1.95335],\n",
       "       [1.71956],\n",
       "       [2.30919],\n",
       "       [2.44191],\n",
       "       [2.77729],\n",
       "       [2.27513],\n",
       "       [2.20857],\n",
       "       [2.24173],\n",
       "       [2.86712],\n",
       "       [1.95637],\n",
       "       [2.44876],\n",
       "       [2.51009],\n",
       "       [2.11773],\n",
       "       [1.78555],\n",
       "       [2.05125],\n",
       "       [1.75873],\n",
       "       [1.46181],\n",
       "       [1.41805],\n",
       "       [1.59541],\n",
       "       [2.80791],\n",
       "       [0.67108],\n",
       "       [1.95071],\n",
       "       [0.89991],\n",
       "       [1.59927],\n",
       "       [1.92313],\n",
       "       [1.94939],\n",
       "       [1.79293],\n",
       "       [1.68135],\n",
       "       [1.95812],\n",
       "       [1.42766],\n",
       "       [1.44395],\n",
       "       [0.99895],\n",
       "       [1.87877],\n",
       "       [0.98195],\n",
       "       [1.38079],\n",
       "       [1.851  ],\n",
       "       [2.7223 ],\n",
       "       [1.94296],\n",
       "       [1.99172],\n",
       "       [1.41723],\n",
       "       [1.46494],\n",
       "       [1.9521 ],\n",
       "       [0.67042],\n",
       "       [1.63328],\n",
       "       [0.32858],\n",
       "       [1.83302],\n",
       "       [1.56726]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1 = np.array(df_2015[['Dystopia Residual']])\n",
    "target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6b449ca-814f-4be4-b732-28958d290a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c88d2299-3a25-44db-b160-0334417e287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4fce100a-56fb-4e77-a8fe-8f5abf572bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test and training split\n",
    "features1_train, features1_test, target1_train, target1_test = train_test_split(\n",
    "    features1, target1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dda084d7-c6cf-4bc2-a3f3-ea7a4ebc7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy regressor\n",
    "dummy = DummyRegressor(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eab65224-03e5-4175-b68f-8afd6cb9b33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Train\" dummy regressor\n",
    "dummy.fit(features1_train, target1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7b4acd3a-37f2-4492-bbcf-4bed687f178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0009556857877641711"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get R-squared score\n",
    "dummy.score(features1_test, target1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ab65296-d988-4e15-8284-96572f63ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare, we train our model and evaluate the performance score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a258158a-565b-4128-b015-35e8249123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b5fe418f-e5cf-4e65-a834-e6bcf052001d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train simple linear regression model\n",
    "ols = LinearRegression()\n",
    "ols.fit(features1_train, target1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55606281-9151-441f-a493-de35a0dfd032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999648899115"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get R-squared score\n",
    "ols.score(features1_test, target1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd4f31-45c8-41b6-ac58-4c93c1f242c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "253594ad-1843-4825-b8f9-2db505ecba24",
   "metadata": {},
   "source": [
    "# 11.3 Creating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fbf150cb-c8f0-4b4e-9a69-274a3ef76313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59743e9b-1cc7-461c-a76f-90aada793202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>23500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0        385       0   35         20000          0\n",
       "1        681       0   40         43500          0\n",
       "2        353       0   49         74000          0\n",
       "3        895       0   40        107500          1\n",
       "4        661       0   25         79000          0\n",
       "..       ...     ...  ...           ...        ...\n",
       "995      863       0   38         59000          0\n",
       "996      800       1   47         23500          0\n",
       "997      407       1   28        138500          1\n",
       "998      299       1   48        134000          1\n",
       "999      687       1   44         73500          0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "471ae2c0-a614-414e-a10f-32e6173bbed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,     35,  20000],\n",
       "       [     0,     40,  43500],\n",
       "       [     0,     49,  74000],\n",
       "       ...,\n",
       "       [     1,     28, 138500],\n",
       "       [     1,     48, 134000],\n",
       "       [     1,     44,  73500]], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(df[['Gender', 'Age', 'AnnualSalary']])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f5ffdb7a-83ef-4423-bc97-88f6233289b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5c96b28d-7319-4d6c-9ecc-7e4500d9a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5a76bc82-a193-46a6-9550-a58b5819a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy classifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "51bbe4af-b237-4b38-8ef8-3e05cf836ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(random_state=1, strategy=&#x27;uniform&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(random_state=1, strategy=&#x27;uniform&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(random_state=1, strategy='uniform')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Train\" model\n",
    "dummy.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c130ba9-6e31-4445-970d-a9b39e99fa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get accuracy score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2b5d7d2d-772b-42e3-aa2d-a96ebb60ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By comparing the baseline classifier to our trained classifier, we can see the improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8553ab95-e086-463d-b68d-7d09785713b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3440c40c-305f-437b-a442-06046890a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9bd5aa0c-92f1-47b4-a93e-5b2770df0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oluwaseun Alade\\AppData\\Local\\Temp\\ipykernel_9052\\1099743955.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(features_train, target_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "classifier.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "64f80f87-031f-4baa-9011-bf307fbcdb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get accuracy score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b758fc5-2269-4441-8680-4f9af2d3de82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90cb027-1194-4ebf-ab9e-fea7911b834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58c01f-a244-4014-95d7-e7aa0644da58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa39e9b-a15e-49a0-8177-05f50417146c",
   "metadata": {},
   "source": [
    "# Plotting, Visualization, and Storytelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7c3da9b4-a7b2-44f9-b588-f89cdd19120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0      385       0   35         20000          0\n",
       "1      681       0   40         43500          0\n",
       "2      353       0   49         74000          0\n",
       "3      895       0   40        107500          1\n",
       "4      661       0   25         79000          0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "386a9e8b-8979-49f5-89ac-f18252c59de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>132500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>84500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>790</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>72500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>108000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>149000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>136500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>951</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>104000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "6        219       1   46        132500          1\n",
       "8         85       1   30         84500          0\n",
       "12       790       1   32         72500          0\n",
       "14       118       1   42        108000          1\n",
       "15        54       1   33        149000          1\n",
       "..       ...     ...  ...           ...        ...\n",
       "993      476       1   54        136500          0\n",
       "994      951       1   53        104000          1\n",
       "997      407       1   28        138500          1\n",
       "998      299       1   48        134000          1\n",
       "999      687       1   44         73500          0\n",
       "\n",
       "[306 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df[(df.Gender == 1) &\n",
    "                (df.Age >20) & \n",
    "                (df.AnnualSalary >60000)]\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "abaff796-a6c4-43bd-a528-21989ea9f929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 5)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2116be94-e2ce-4491-b22a-396ec8cd95e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>151500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>941</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>150500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>966</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>149500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>149000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>61500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>61500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>61000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>60500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>60500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "95       485       1   33        151500          1\n",
       "272      941       1   34        150500          1\n",
       "570      966       1   32        150000          1\n",
       "297      130       1   38        149500          1\n",
       "15        54       1   33        149000          1\n",
       "..       ...     ...  ...           ...        ...\n",
       "573      893       1   42         61500          0\n",
       "927      388       1   36         61500          0\n",
       "866      908       1   39         61000          0\n",
       "49        27       1   40         60500          0\n",
       "774       74       1   29         60500          0\n",
       "\n",
       "[306 rows x 5 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df_results.sort_values(by='AnnualSalary', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0e73e-4596-4c9a-a8db-5784b4d3c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to visually display the distribution of the values in the AnnualSalary column. \n",
    "# We can pass an array of values into the default hist() plot using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ee862bdf-c079-4a28-8701-361db85c919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results.hist(column='AnnualSalary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f1e20f0f-984a-424c-a1bf-2cd5c1528763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       306.000000\n",
       "mean      98068.627451\n",
       "std       26867.498729\n",
       "min       60500.000000\n",
       "25%       75000.000000\n",
       "50%       89500.000000\n",
       "75%      118500.000000\n",
       "max      151500.000000\n",
       "Name: AnnualSalary, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[\"AnnualSalary\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a9faa-2bb3-46d5-999c-78506d18881d",
   "metadata": {},
   "source": [
    "# Understanding outliers and trends\n",
    "# BOX PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715cef01-90de-48b9-9637-e54b84751e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue to analyze our existing dataset and see how it would be visualized using a\n",
    "# box plot. Similar to the prior example, we will load all of the data from the source into a\n",
    "# single DataFrame and then create a subset DataFrame using filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd341762-564b-48ec-b5a9-a9b1ff675acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following libraries by adding the following command in your Jupyter\n",
    "# Notebook and run the cell. Feel free to follow along by creating your own\n",
    "# Notebook; I have placed a copy on GitHub for reference:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcafa057-0b9c-4a3f-93fa-fba809f5d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Dystopia Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "      <td>0.03411</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>2.51738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "      <td>0.04884</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.43630</td>\n",
       "      <td>2.70201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>2.49204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "      <td>0.03880</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>2.46531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>0.03553</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>2.45176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country          Region  Happiness Rank  Happiness Score  \\\n",
       "0  Switzerland  Western Europe               1            7.587   \n",
       "1      Iceland  Western Europe               2            7.561   \n",
       "2      Denmark  Western Europe               3            7.527   \n",
       "3       Norway  Western Europe               4            7.522   \n",
       "4       Canada   North America               5            7.427   \n",
       "\n",
       "   Standard Error  Economy (GDP per Capita)   Family  \\\n",
       "0         0.03411                   1.39651  1.34951   \n",
       "1         0.04884                   1.30232  1.40223   \n",
       "2         0.03328                   1.32548  1.36058   \n",
       "3         0.03880                   1.45900  1.33095   \n",
       "4         0.03553                   1.32629  1.32261   \n",
       "\n",
       "   Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
       "0                   0.94143  0.66557                        0.41978   \n",
       "1                   0.94784  0.62877                        0.14145   \n",
       "2                   0.87464  0.64938                        0.48357   \n",
       "3                   0.88521  0.66973                        0.36503   \n",
       "4                   0.90563  0.63297                        0.32957   \n",
       "\n",
       "   Generosity  Dystopia Residual  \n",
       "0     0.29678            2.51738  \n",
       "1     0.43630            2.70201  \n",
       "2     0.34139            2.49204  \n",
       "3     0.34699            2.46531  \n",
       "4     0.45811            2.45176  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df_2015 = pd.read_csv('2015.csv', header=0)\n",
    "df_2015.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65302345-b16a-444c-affc-c2d9eff8d1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4da9b8d4-fc25-4458-8495-d1017de49519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Dystopia Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "      <td>0.03411</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>2.51738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>2.49204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "      <td>0.03880</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>2.46531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>0.03553</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>2.45176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>6</td>\n",
       "      <td>7.406</td>\n",
       "      <td>0.03140</td>\n",
       "      <td>1.29025</td>\n",
       "      <td>1.31826</td>\n",
       "      <td>0.88911</td>\n",
       "      <td>0.64169</td>\n",
       "      <td>0.41372</td>\n",
       "      <td>0.23351</td>\n",
       "      <td>2.61955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country          Region  Happiness Rank  Happiness Score  \\\n",
       "0  Switzerland  Western Europe               1            7.587   \n",
       "2      Denmark  Western Europe               3            7.527   \n",
       "3       Norway  Western Europe               4            7.522   \n",
       "4       Canada   North America               5            7.427   \n",
       "5      Finland  Western Europe               6            7.406   \n",
       "\n",
       "   Standard Error  Economy (GDP per Capita)   Family  \\\n",
       "0         0.03411                   1.39651  1.34951   \n",
       "2         0.03328                   1.32548  1.36058   \n",
       "3         0.03880                   1.45900  1.33095   \n",
       "4         0.03553                   1.32629  1.32261   \n",
       "5         0.03140                   1.29025  1.31826   \n",
       "\n",
       "   Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
       "0                   0.94143  0.66557                        0.41978   \n",
       "2                   0.87464  0.64938                        0.48357   \n",
       "3                   0.88521  0.66973                        0.36503   \n",
       "4                   0.90563  0.63297                        0.32957   \n",
       "5                   0.88911  0.64169                        0.41372   \n",
       "\n",
       "   Generosity  Dystopia Residual  \n",
       "0     0.29678            2.51738  \n",
       "2     0.34139            2.49204  \n",
       "3     0.34699            2.46531  \n",
       "4     0.45811            2.45176  \n",
       "5     0.23351            2.61955  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter our dataFrame for the information we want to focus on.\n",
    "df_results = df_2015[(df_2015.Family <1.40) & \n",
    "                     ((df_2015.Region == 'Western Europe') | (df_2015.Region == 'North America'))]\n",
    "\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c06f9343-cbe3-4c1f-b6ae-4701ab315eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2277ed86-0df1-4a81-9eb7-2d9bf97c2e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results.hist(column='Dystopia Residual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1d2e254-e16c-4ffc-bb7f-1ce858c83394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22.000000\n",
       "mean      2.156125\n",
       "std       0.365310\n",
       "min       1.264620\n",
       "25%       1.969693\n",
       "50%       2.167465\n",
       "75%       2.465603\n",
       "max       2.619550\n",
       "Name: Dystopia Residual, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['Dystopia Residual'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecaa30aa-778a-426f-9bd9-deec6b8af78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e71fffa0-3a4c-4a58-b5dd-65fca8bcd005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Generosity'}, xlabel='Region'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results.boxplot(by='Region', column=['Generosity'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1d6ac-9725-49f7-87da-ae71f380cf33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e0486-f2cb-4daa-81e5-273798b0bff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c018c97-b7e7-40c0-86ce-244058ce5167",
   "metadata": {},
   "source": [
    "# 12.1 Selecting Best Models Using Exhaustive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "26328c28-92b0-4548-993c-a12b19199bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "colors=['#9db1f8','#217a36','#47bc8f','#947efd','#a4d835']\n",
    "sns.set_palette(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b26749eb-9b2e-46d9-90e7-38657c04ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID Gender  Age  AnnualSalary  Purchased\n",
       "0      385   Male   35         20000          0\n",
       "1      681   Male   40         43500          0\n",
       "2      353   Male   49         74000          0\n",
       "3      895   Male   40        107500          1\n",
       "4      661   Male   25         79000          0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"car_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a03bd00a-402e-41bf-8dbb-ccc358fb6c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>23500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0        385       0   35         20000          0\n",
       "1        681       0   40         43500          0\n",
       "2        353       0   49         74000          0\n",
       "3        895       0   40        107500          1\n",
       "4        661       0   25         79000          0\n",
       "..       ...     ...  ...           ...        ...\n",
       "995      863       0   38         59000          0\n",
       "996      800       1   47         23500          0\n",
       "997      407       1   28        138500          1\n",
       "998      299       1   48        134000          1\n",
       "999      687       1   44         73500          0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = pd.factorize(df['Gender'])[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "35ee570f-fa24-4cb4-9590-b664540e5836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca69e31a-69b3-40ca-8042-a439554a1baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,     35,  20000],\n",
       "       [     0,     40,  43500],\n",
       "       [     0,     49,  74000],\n",
       "       ...,\n",
       "       [     1,     28, 138500],\n",
       "       [     1,     48, 134000],\n",
       "       [     1,     44,  73500]], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(df[['Gender', 'Age', 'AnnualSalary']])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57058b82-a295-4426-b989-c6681e481102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array(df[['Purchased']])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e57df9b-f40d-4273-9f33-8646dc2ea6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn’s GridSearchCV:\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "054c9612-548a-4b56-929a-e77f17972648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "017f8fb4-c4f7-4dfd-b2df-73677e626a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range of candidate penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "27535d00-4cce-440c-a841-e064ce582a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range of candidate regularization hyperparameter values\n",
    "C = np.logspace(0, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75b25f1b-71ba-494f-96d2-74fe28df0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary hyperparameter candidates\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9c9997d8-578d-4283-957b-456cd8d682eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff954c6c-e8ee-47db-b36f-71fc1a73097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "100 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [  nan 0.581   nan 0.581   nan 0.581   nan 0.581   nan 0.581   nan 0.581\n",
      "   nan 0.581   nan 0.581   nan 0.581   nan 0.581   nan 0.581   nan 0.581\n",
      "   nan 0.581   nan 0.581   nan 0.581   nan 0.581   nan 0.581   nan 0.581\n",
      "   nan 0.581   nan 0.581]\n",
      "  warnings.warn(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "40043ebf-7ee4-46c6-b3d8-1c90a8ede751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6b124d54-b9f2-45fc-8407-36eb3d168939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cacbe439-1d08-49fd-b2b0-2de296eab488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421807e5-2fad-4cc4-b0d2-7767af54e8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a4bc0-aa5f-4686-9db8-a4ebb8b8c65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35bf2693-1ad8-4f83-9253-b86ccf5720c6",
   "metadata": {},
   "source": [
    "# 12.2 Selecting Best Models Using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fab92a1-fb9c-4784-9acf-5950936531d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID Gender  Age  AnnualSalary  Purchased\n",
       "0      385   Male   35         20000          0\n",
       "1      681   Male   40         43500          0\n",
       "2      353   Male   49         74000          0\n",
       "3      895   Male   40        107500          1\n",
       "4      661   Male   25         79000          0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"car_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e14b9e-577a-474c-9a59-2083db86ad32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>33500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>132500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>588</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>84500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>465</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0      385       0   35         20000          0\n",
       "1      681       0   40         43500          0\n",
       "2      353       0   49         74000          0\n",
       "3      895       0   40        107500          1\n",
       "4      661       0   25         79000          0\n",
       "5      846       1   47         33500          1\n",
       "6      219       1   46        132500          1\n",
       "7      588       0   42         64000          0\n",
       "8       85       1   30         84500          0\n",
       "9      465       0   41         52000          0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = pd.factorize(df['Gender'])[0]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72d5be20-e85b-4507-8682-1441c5c6dd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8893daad-8890-4780-989b-cc00c930851f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bbf2ef2-36d9-45de-8a1b-cee33c59a181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    35,  20000],\n",
       "       [    40,  43500],\n",
       "       [    49,  74000],\n",
       "       ...,\n",
       "       [    28, 138500],\n",
       "       [    48, 134000],\n",
       "       [    44,  73500]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(df[['Age', 'AnnualSalary']])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d187cd0-1f73-4b9a-865a-49da3936da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array(df[['Purchased']])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d620be57-ab52-485f-a9a7-e8b3ad0a7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem\n",
    "# You want a computationally cheaper method than exhaustive search to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "95f89c94-7e6c-4ef5-b6f2-48bd5e70f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn’s RandomizedSearchCV:\n",
    "# Load libraries\n",
    "from scipy.stats import uniform\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a044ece-e74b-4d6a-b22e-ddfb88a194ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    35,  20000],\n",
       "       [    40,  43500],\n",
       "       [    49,  74000],\n",
       "       ...,\n",
       "       [    28, 138500],\n",
       "       [    48, 134000],\n",
       "       [    44,  73500]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78f649fc-3d7d-41cd-a775-41ce5e6f79f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "895aa019-76fa-435d-9338-151335a56567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba13daa4-07f8-415e-974a-a9afa5a46788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range of candidate regularization penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "170d0c32-3294-4faf-b8f8-10ac8defa615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution of candidate regularization hyperparameter values\n",
    "C = uniform(loc=0, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5512074c-afc7-457f-b7ab-fda9bd335818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d79bb42a-0eac-4bdd-ba6e-dbe9445461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create randomized search\n",
    "randomizedsearch = RandomizedSearchCV(\n",
    "    logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6248c9a0-b5b5-4cc1-83dc-26647cb61c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "230 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "230 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [  nan 0.582 0.582 0.582 0.582 0.582   nan   nan   nan   nan 0.582 0.582\n",
      "   nan 0.582 0.582 0.582   nan   nan 0.582   nan 0.582 0.582   nan 0.582\n",
      "   nan 0.582 0.582 0.582 0.582 0.582 0.582   nan   nan 0.582   nan   nan\n",
      " 0.582 0.582   nan   nan 0.582 0.582   nan   nan   nan 0.582 0.582 0.582\n",
      "   nan 0.582   nan   nan 0.582   nan 0.582   nan   nan   nan   nan   nan\n",
      " 0.582   nan   nan   nan   nan 0.582   nan   nan 0.582 0.582   nan   nan\n",
      " 0.582 0.582   nan   nan 0.582 0.582 0.582 0.582 0.582   nan 0.582 0.582\n",
      " 0.582   nan 0.582   nan 0.582 0.582 0.582 0.582   nan 0.582   nan   nan\n",
      "   nan 0.582 0.582 0.582]\n",
      "  warnings.warn(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit randomized search\n",
    "best_model = randomizedsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed3c4cb9-eb1d-4aea-988c-747a1436f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.11348353, 2.86616959, 2.34577221, 1.30127595, 0.65403508,\n",
       "       1.16305449, 0.35308319, 2.51952383, 0.09215024, 3.65993372])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a uniform distribution between 0 and 4, sample 10 values\n",
    "uniform(loc=0, scale=4).rvs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff10f51e-2189-4894-828d-510cd09a1291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 3.730229437354635\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ff466d3-82bd-4d9f-87a1-dd4c5ce78fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577ffaf-e5a5-4f6d-94da-833695f7db12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d4239-ed28-410b-9c96-cd33dfe3bf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c23fd-d706-4188-81d8-bb5c4331f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = input(\"Enter Your age: \")\n",
    "firstName = input(\"Enter your firstname: \")\n",
    "myAge = int(age)\n",
    "firstName = str(firstName)\n",
    "calculation = 2022-myAge+100\n",
    "finalAge = str(calculation)\n",
    "\n",
    "print(\"Hello \" + firstName + \", you will 100years in \" + finalAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31431401-edb6-4fad-8bdb-6298999ec5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf010f70-c580-4e62-bf0c-b98b059a2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = input(\"Enter your Number: \")\n",
    "if (number%2)>0:\n",
    "    print(\"The number input is Odd Number\")\n",
    "else:\n",
    "    print(\"The number input is Even Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51ec4d-0f17-4c05-97ec-cc16f500c4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac8f6a-651e-456f-a5dd-ec61305c2903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fdd912-1081-4d5d-9047-dd3a6a7f5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a number:  10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "8\n",
      "10\n",
      "16\n",
      "20\n",
      "25\n",
      "40\n",
      "50\n",
      "80\n",
      "100\n",
      "125\n",
      "200\n",
      "250\n",
      "400\n",
      "500\n",
      "625\n",
      "1000\n",
      "1250\n",
      "2000\n",
      "2500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "number = input(\"Enter a number: \")\n",
    "my_integerNumber = int(number)\n",
    "half = int(my_integerNumber/2)\n",
    "for i in range(1, (half+1), 1):\n",
    "    if my_integerNumber%i ==0: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6effd2-d769-4f68-bbd3-40663d2fb4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddb8349-440d-492a-b756-431009360a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]\n",
    "b = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "common = []\n",
    "for i in a and b:\n",
    "    common.append(i)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b4101-3be6-4dd3-b6f2-4cf0557cad35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b44e149-639b-4575-816e-02ad1d40fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# Python program to find out the average of a set of integers\n",
    "integerNumber = (10,10,10,10,10)\n",
    "sum = 0\n",
    "for i in integerNumber:\n",
    "    sum = sum + i\n",
    "    \n",
    "print(sum/len(integerNumber))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308da69e-567d-451f-bb06-81e8322ed068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a13a6-df9d-4d13-8736-34be7604e7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f994046-382b-42dd-be25-2ad50b5d5334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Python program to find the product of a set of real numbers\n",
    "\n",
    "realNumber = (10,10,10,5)\n",
    "product = 1\n",
    "for i in realNumber:\n",
    "    product = product * i\n",
    "    \n",
    "print(product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eceee8-a963-4fbd-bc90-85bc02b12161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c707117-f390-49f3-ab8a-604ede49cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Integer:  56789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['56789']\n"
     ]
    }
   ],
   "source": [
    "# Python program to convert integer to string\n",
    "integerNumber = input(\"Enter your Integer: \")\n",
    "splitNumber = integerNumber.split(\",\")\n",
    "print(splitNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fa364-9e7b-4757-b058-37108c163e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861291dc-43d7-440c-9785-eb79dc01643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input your string:  oyo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string is Palindrome\n"
     ]
    }
   ],
   "source": [
    "mystring = input(\"Input your string: \")\n",
    "reverseString = mystring[::-1]\n",
    "if mystring == reverseString:\n",
    "    print(\"The string is Palindrome\")\n",
    "else:\n",
    "    print(\"The string is not palindrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73408c-a976-46a4-808a-11685423e50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a9d34e1-65ab-4b29-95f4-4e0381e0a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your chosen integer:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "myInput = input(\"Enter your chosen integer: \")\n",
    "convertInteger = int(myInput)\n",
    "sum=0\n",
    "for i in range(1,(convertInteger+1),1):\n",
    "    sum = sum + i\n",
    "print(sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3d1f61f-a429-4fc8-ad76-316a570e950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myInputNumber(myInput):\n",
    "    if type(myInput)!= int: \n",
    "        sum=0\n",
    "    else:\n",
    "        sum=0\n",
    "        for i in range(1,(myInput+1),1):\n",
    "            sum = sum + i\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e76f1e84-a857-45c6-8724-1533371b28c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "myInputNumber(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78baad3f-9667-40f6-8cb4-0ebde9288ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f3ffb3d-5240-4abe-8672-d8e0473ef8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Python program to find the sum of the digits of an integer\n",
    "number = input(\"Enter the number: \")\n",
    "digits = []\n",
    "arrayNumber = []\n",
    "sum=0\n",
    "for i in number: \n",
    "    digits.append(i)\n",
    "for j in digits: \n",
    "    arrayNumber.append(int(j))\n",
    "    \n",
    "for k in arrayNumber:\n",
    "    sum = sum + k\n",
    "\n",
    "print(sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179056bb-4f03-4ad9-8a6d-e951a0ec2630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366cd919-8ea2-4fd8-9b37-c7785c972f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number:  12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12345']\n"
     ]
    }
   ],
   "source": [
    "# Python program to find the sum of the digits of an integer\n",
    "number = input(\"Enter the number: \")\n",
    "\n",
    "stringnum = number.split(\",\")\n",
    "\n",
    "print(stringnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94d180-44bf-44e8-abd3-79fae224073b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f0d2cf-da44-40f6-81d3-12395bc6e58e",
   "metadata": {},
   "source": [
    "# Python program to display all integers within the range 100-200 whose sum of digits is an \n",
    "# even number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "595a8d14-41f6-4571-a11a-59b266791322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to display all integers within the range 100-200 whose sum of digits is an \n",
    "# even number.\n",
    "\n",
    "def sumdigitEven(my_range):\n",
    "    even_number_list = []\n",
    "    for i in range(my_range[0], my_range[1], 1):\n",
    "        sum=0\n",
    "        for j in str(i):\n",
    "            sum=sum+int(j)\n",
    "        if (sum%2)==0:\n",
    "            even_number_list.append(i)\n",
    "                \n",
    "    return even_number_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1c56d80-b60d-4685-8919-2f5c8f228655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 103,\n",
       " 105,\n",
       " 107,\n",
       " 109,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 121,\n",
       " 123,\n",
       " 125,\n",
       " 127,\n",
       " 129,\n",
       " 130,\n",
       " 132,\n",
       " 134,\n",
       " 136,\n",
       " 138,\n",
       " 141,\n",
       " 143,\n",
       " 145,\n",
       " 147,\n",
       " 149,\n",
       " 150,\n",
       " 152,\n",
       " 154,\n",
       " 156,\n",
       " 158,\n",
       " 161,\n",
       " 163,\n",
       " 165,\n",
       " 167,\n",
       " 169,\n",
       " 170,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 178,\n",
       " 181,\n",
       " 183,\n",
       " 185,\n",
       " 187,\n",
       " 189,\n",
       " 190,\n",
       " 192,\n",
       " 194,\n",
       " 196,\n",
       " 198]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_range = [100, 200]\n",
    "sumdigitEven(my_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74d99f5c-334d-4e73-9bee-71a178742c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to display all integers within the range 100-200 whose sum of digits is an \n",
    "# even number.\n",
    "\n",
    "def sumdigitEven(my_range):\n",
    "    even_number_list = []\n",
    "    for i in range(my_range[0], my_range[1], 1):\n",
    "        sum=0\n",
    "        for j in str(i):\n",
    "            sum=sum+int(j)\n",
    "        if (sum%2)==0:\n",
    "            even_number_list.append(i)\n",
    "                \n",
    "    return even_number_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0073436-a78a-416b-b3fa-de83f3ef8213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 103,\n",
       " 105,\n",
       " 107,\n",
       " 109,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 121,\n",
       " 123,\n",
       " 125,\n",
       " 127,\n",
       " 129,\n",
       " 130,\n",
       " 132,\n",
       " 134,\n",
       " 136,\n",
       " 138,\n",
       " 141,\n",
       " 143,\n",
       " 145,\n",
       " 147,\n",
       " 149,\n",
       " 150,\n",
       " 152,\n",
       " 154,\n",
       " 156,\n",
       " 158,\n",
       " 161,\n",
       " 163,\n",
       " 165,\n",
       " 167,\n",
       " 169,\n",
       " 170,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 178,\n",
       " 181,\n",
       " 183,\n",
       " 185,\n",
       " 187,\n",
       " 189,\n",
       " 190,\n",
       " 192,\n",
       " 194,\n",
       " 196,\n",
       " 198]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_range = [100, 200]\n",
    "sumdigitEven(my_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604e10b-878d-41b3-b3ae-711747ed6044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4056306-f1ce-4f13-bc65-58da42de27ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your integer:  500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Python program to find the sum of the digits of an integer.\n",
    "integerNum = input(\"Enter your integer: \")\n",
    "intArray = []\n",
    "sum = 0\n",
    "for i in integerNum:\n",
    "    intArray.append(int(i))\n",
    "for j in intArray:\n",
    "    sum = sum + j\n",
    "    \n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "087f3006-e5f8-4e10-8101-7f8f355d2e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to check if a given integer is a prime number or not\n",
    "integerNum = input(\"Enter the Integer: \")\n",
    "my_integer = int(integerNum)\n",
    "checklist = []\n",
    "for i in range(2, my_integer, 1):\n",
    "    if (my_integer%i) == 0:\n",
    "        checklist.append(1)   # Check for not prime number and returns 1\n",
    "    else:\n",
    "        checklist.append(2)  # check for prime number and returns 2\n",
    "\n",
    "y = checklist.count(1)   # Not a prime number\n",
    "x = checklist.count(2)   # a prime number\n",
    "        \n",
    "if y>1:\n",
    "    print(\"Not Prime Number\")\n",
    "else:\n",
    "    print(\"Prime Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b87d831a-69d7-4c2e-a9aa-7fc35f399d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not prime number'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_prime(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c12ee7a-2790-4f3a-a94f-ce411e417935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to check if a given integer is a prime number or not\n",
    "def is_prime(n):\n",
    "    for i in range(2,n):\n",
    "        if (n%i) == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c972599c-e270-431e-96fc-ed5b688dc6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_prime(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c46d9a-327b-4e88-9d51-d3e885401bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to display all the multiples of 3 within the range 10 to 50\n",
    "\n",
    "def multiple_of_three(my_range):\n",
    "    my_multiple = []\n",
    "    for i in range(my_range[0], my_range[1], 1):\n",
    "        if (i%3)==0: my_multiple.append(i)\n",
    "    return my_multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f22b7e4-caf6-41f6-ae8a-9b1b4a517fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_range=[10,50]\n",
    "multiple_of_three(my_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a527699-57ee-4410-b949-91141b363d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a9dbb1c-112e-439d-9427-97d962d7e7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Integer:  17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime Number\n"
     ]
    }
   ],
   "source": [
    "# Python program to check if a given integer is a prime number or not\n",
    "integerNum = input(\"Enter the Integer: \")\n",
    "my_integer = int(integerNum)\n",
    "checklist = []\n",
    "for i in range(2, my_integer, 1):\n",
    "    if (my_integer%i) == 0:\n",
    "        checklist.append(1)   # Check for not prime number and returns 1\n",
    "    else:\n",
    "        checklist.append(2)  # check for prime number and returns 2\n",
    "\n",
    "y = checklist.count(1)   # Not a prime number\n",
    "x = checklist.count(2)   # a prime number\n",
    "        \n",
    "if y>1:\n",
    "    print(\"Not Prime Number\")\n",
    "else:\n",
    "    print(\"Prime Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32addec5-2df8-4b11-8bb3-b2b72ebd11d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6924884-522b-4696-b8b0-cc06c9943d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472cfbee-3545-4202-9fe1-c738a9a4a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "class Number:\n",
    "    def addition(self, a, b):\n",
    "        return (a+b)\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        print (x+y)\n",
    "    \n",
    "    \n",
    "d = Number(10, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ec54f-4bc4-4771-9ea2-53b9e7805b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3197407-6cec-4311-8335-4a2d1b9658d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n"
     ]
    }
   ],
   "source": [
    "class Student:\n",
    "    def __init__(self, name, age, grade):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.grade = grade     # 0 to 100\n",
    "        \n",
    "    def get_grade(self):\n",
    "        return self.grade\n",
    "    \n",
    "    \n",
    "\n",
    "class Course:\n",
    "    def __init__(self, name, max_students):\n",
    "        self.name = name\n",
    "        self.max_students = max_students\n",
    "        self.students = []\n",
    "        \n",
    "    def add_student(self, student):\n",
    "        if len(self.students) < self.max_students:\n",
    "            self.students.append(student)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_average_grade(self):\n",
    "        value = 0\n",
    "        for student in self.students:\n",
    "            value += student.get_grade()\n",
    "        return value/len(self.students)\n",
    "        \n",
    "\n",
    "s1 = Student(\"Tim\", 19, 95)\n",
    "s2 = Student(\"Bill\", 19, 75)\n",
    "s3 = Student(\"Jill\", 19, 65)\n",
    "\n",
    "course = Course(\"Science\", 2)\n",
    "course.add_student(s1)\n",
    "course.add_student(s2)\n",
    "course.add_student(s3)\n",
    "\n",
    "print(course.get_average_grade())\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72d8e8-9aff-44e2-b0bb-d0ed40709c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3dbbd03-20b6-4462-8836-22d63574f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number:  120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prime from 1 to 120 are [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113]\n"
     ]
    }
   ],
   "source": [
    "# Python program to generate the prime numbers from 1 to N\n",
    "\n",
    "number_N = input(\"Enter the number: \")\n",
    "integer_N = int(number_N)\n",
    "prime_number = []\n",
    "\n",
    "for i in range(2, integer_N+1, 1):  # List of integers to be used as divisors for the input integer N\n",
    "    check = []\n",
    "    for j in range(2, i, 1):\n",
    "        remains = (i % j)\n",
    "        check.append(remains)\n",
    "    y = check.count(0)\n",
    "    if y==0:\n",
    "        prime_number.append(i)\n",
    "                      \n",
    "print(\"The prime from 1 to \" + number_N + \" are \" + str(prime_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029c44e-4d8d-4f48-ad90-6f5b7bd7df00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17cc289-9de7-4cd3-966a-75e8b4f086c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50eece7d-dce1-4a1f-a48e-20de41a6b77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Firstname: funmilayo) (Lastname: ogunfolabi) (EmployeeID: emp001) (Tax: 40000.0)\n",
      "None\n",
      "(Firstname: Lawrence) (Lastname: Alade) (EmployeeID: emp002) (Tax: 50000.0)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Employee:\n",
    "    \n",
    "    def __init__(self, firstname, lastname, employeeid, position, salary):\n",
    "        self.firstname = firstname\n",
    "        self.lastname = lastname\n",
    "        self.employeeid = employeeid\n",
    "        self.position = position\n",
    "        self.salary = salary\n",
    "        \n",
    "    def compute_employee_tax(self):\n",
    "        tax = (self.salary) * (10/100)\n",
    "        print (f\"(Firstname: {self.firstname}) (Lastname: {self.lastname}) (EmployeeID: {self.employeeid}) (Tax: {tax})\")\n",
    "        \n",
    "           \n",
    "    def __str__(self):\n",
    "            return f\"(Firstname: {self.firstname}) (Lastname: {self.lastname}) (Employee: {self.employeeid})\"\n",
    "        \n",
    "    \n",
    "\n",
    "              \n",
    "        \n",
    "employee_001 = Employee(\"funmilayo\", \"ogunfolabi\", \"emp001\", \"sales manager\", 400000)\n",
    "employee_002 = Employee(\"Lawrence\", \"Alade\", \"emp002\", \"General Manager\", 500000)\n",
    "\n",
    "\n",
    "print(employee_001.compute_employee_tax())\n",
    "print(employee_002.compute_employee_tax())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c6a9e8-2bd6-4280-ac1c-d71732d8da07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'funmilayo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_001.firstname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8982daaa-62f6-47cd-904c-9b1cb68563e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_002.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7e6188-3966-4d5b-805e-5858be1bfab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Firstname: funmilayo) (Lastname: ogunfolabi) (Employee: emp001)\n"
     ]
    }
   ],
   "source": [
    "print(employee_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85249e4-bb53-4e26-8f7a-e8a43e645943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6178593-69fb-402d-a09d-9dd315bfda52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
